{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "\n",
    "import ipykernel\n",
    "import pandas as pd\n",
    "\n",
    "#pd.set_option('display.height', 1000)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', 800)\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "pd.set_option('expand_frame_repr', True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "device  = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cuda:0\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import matplotlib.pyplot as plot\n",
    "import numpy as np\n",
    "import os\n",
    "import jsonlines\n",
    "import ast\n",
    "import time, os, fnmatch, shutil\n",
    "from collections import defaultdict\n",
    "import matplotlib\n",
    "import requests\n",
    "\n",
    "import math\n",
    "import random\n",
    "import copy\n",
    "\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "HISTORY_FILE = None\n",
    "\n",
    "summary_dict = {\"losses\":0,\"wins\":0,\"draws\":0}\n",
    "\n",
    "cycle = 0\n",
    "\n",
    "actions = [[], []]\n",
    "rewards = [[], []]\n",
    "history = {\"cycle\": cycle, \"actions\": actions, \"rewards\": rewards, \"value\": 0}\n",
    "\n",
    "score_board = {}\n",
    "#step_action_dict = defaultdict()\n",
    "#step_action_dict['random_moves'] = defaultdict()\n",
    "#step_action_dict['policy_moves'] = defaultdict()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting numeric_names.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile numeric_names.py\n",
    "\n",
    "numeric_names = {'w_R0': 1, 'w_K0': 2, 'w_B0': 3, 'w__K': 4, 'w__Q': 5, 'w_B1': 6, 'w_K1': 7, 'w_R1': 8, 'w_P0': 9, 'w_P1':\n",
    " 10, 'w_P2': 11, 'w_P3': 12, 'w_P4': 13, 'w_P5': 14, 'w_P6': 15, 'w_P7': 16, 'b_P0': -16, 'b_P1': -15, 'b_P2': -14, 'b_P3':\n",
    " -13, 'b_P4': -12, 'b_P5': -11, 'b_P6': -10, 'b_P7': -9, 'b_R0': -8, 'b_K0': -7, 'b_B0': -6, 'b__K': -5, 'b__Q': -4, 'b_B1'\n",
    ": -3, 'b_K1': -2, 'b_R1': -1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1,1,0': 0, '2,1,-2': 1, '2,1,2': 2, '2,2,-1': 3, '2,2,1': 4, '3,1,-1': 5, '3,1,1': 6, '4,1,-1': 7, '4,1,0': 8, '4,1,1': 9, '5,1,-1': 10, '5,1,0': 11, '5,1,1': 12, '6,1,-1': 13, '6,1,1': 14, '7,1,-2': 15, '7,1,2': 16, '7,2,-1': 17, '7,2,1': 18, '8,1,0': 19, '9,1,0': 20, '9,1,-1': 21, '9,1,1': 22, '10,1,0': 23, '10,1,-1': 24, '10,1,1': 25, '11,1,0': 26, '11,1,-1': 27, '11,1,1': 28, '12,1,0': 29, '12,1,-1': 30, '12,1,1': 31, '13,1,0': 32, '13,1,-1': 33, '13,1,1': 34, '14,1,0': 35, '14,1,-1': 36, '14,1,1': 37, '15,1,0': 38, '15,1,-1': 39, '15,1,1': 40, '16,1,0': 41, '16,1,-1': 42, '16,1,1': 43, '-16,-1,0': 44, '-16,-1,-1': 45, '-16,-1,1': 46, '-15,-1,0': 47, '-15,-1,-1': 48, '-15,-1,1': 49, '-14,-1,0': 50, '-14,-1,-1': 51, '-14,-1,1': 52, '-13,-1,0': 53, '-13,-1,-1': 54, '-13,-1,1': 55, '-12,-1,0': 56, '-12,-1,-1': 57, '-12,-1,1': 58, '-11,-1,0': 59, '-11,-1,-1': 60, '-11,-1,1': 61, '-10,-1,0': 62, '-10,-1,-1': 63, '-10,-1,1': 64, '-9,-1,0': 65, '-9,-1,-1': 66, '-9,-1,1': 67, '-8,-1,0': 68, '-7,-1,-2': 69, '-7,-1,2': 70, '-7,-2,-1': 71, '-7,-2,1': 72, '-6,-1,-1': 73, '-6,-1,1': 74, '-5,-1,-1': 75, '-5,-1,0': 76, '-5,-1,1': 77, '-4,-1,-1': 78, '-4,-1,0': 79, '-4,-1,1': 80, '-3,-1,-1': 81, '-3,-1,1': 82, '-2,-1,-2': 83, '-2,-1,2': 84, '-2,-2,-1': 85, '-2,-2,1': 86, '-1,-1,0': 87}\n",
      "{0: '1,1,0', 1: '2,1,-2', 2: '2,1,2', 3: '2,2,-1', 4: '2,2,1', 5: '3,1,-1', 6: '3,1,1', 7: '4,1,-1', 8: '4,1,0', 9: '4,1,1', 10: '5,1,-1', 11: '5,1,0', 12: '5,1,1', 13: '6,1,-1', 14: '6,1,1', 15: '7,1,-2', 16: '7,1,2', 17: '7,2,-1', 18: '7,2,1', 19: '8,1,0', 20: '9,1,0', 21: '9,1,-1', 22: '9,1,1', 23: '10,1,0', 24: '10,1,-1', 25: '10,1,1', 26: '11,1,0', 27: '11,1,-1', 28: '11,1,1', 29: '12,1,0', 30: '12,1,-1', 31: '12,1,1', 32: '13,1,0', 33: '13,1,-1', 34: '13,1,1', 35: '14,1,0', 36: '14,1,-1', 37: '14,1,1', 38: '15,1,0', 39: '15,1,-1', 40: '15,1,1', 41: '16,1,0', 42: '16,1,-1', 43: '16,1,1', 44: '-16,-1,0', 45: '-16,-1,-1', 46: '-16,-1,1', 47: '-15,-1,0', 48: '-15,-1,-1', 49: '-15,-1,1', 50: '-14,-1,0', 51: '-14,-1,-1', 52: '-14,-1,1', 53: '-13,-1,0', 54: '-13,-1,-1', 55: '-13,-1,1', 56: '-12,-1,0', 57: '-12,-1,-1', 58: '-12,-1,1', 59: '-11,-1,0', 60: '-11,-1,-1', 61: '-11,-1,1', 62: '-10,-1,0', 63: '-10,-1,-1', 64: '-10,-1,1', 65: '-9,-1,0', 66: '-9,-1,-1', 67: '-9,-1,1', 68: '-8,-1,0', 69: '-7,-1,-2', 70: '-7,-1,2', 71: '-7,-2,-1', 72: '-7,-2,1', 73: '-6,-1,-1', 74: '-6,-1,1', 75: '-5,-1,-1', 76: '-5,-1,0', 77: '-5,-1,1', 78: '-4,-1,-1', 79: '-4,-1,0', 80: '-4,-1,1', 81: '-3,-1,-1', 82: '-3,-1,1', 83: '-2,-1,-2', 84: '-2,-1,2', 85: '-2,-2,-1', 86: '-2,-2,1', 87: '-1,-1,0'}\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from games import games\n",
    "from numeric_names import numeric_names\n",
    "\n",
    "Pieces_detail = defaultdict()\n",
    "actions_array = []\n",
    "sparse_action_dict = defaultdict()\n",
    "bin_action_dict = defaultdict()\n",
    "actions = []\n",
    "\n",
    "for piece in numeric_names.keys():\n",
    "    action_sparse = []\n",
    "    if piece[0] == 'w':\n",
    "        idx = 0\n",
    "    else:\n",
    "        idx = 1\n",
    "        \n",
    "    if piece[1:3] == '_R':\n",
    "        player_id = 'Rook'\n",
    "    elif piece[1:3] == '_K':\n",
    "        player_id = 'Knight'\n",
    "    elif piece[1:3] == '_B':\n",
    "        player_id = 'Bishop'\n",
    "    elif piece[1:3] == '_P':\n",
    "        player_id = 'Pawn'\n",
    "    elif piece[1:4] == '__K':\n",
    "        player_id = 'King'\n",
    "    elif piece[:3] == '__Q':\n",
    "        player_id = 'Queen'\n",
    "        \n",
    "    actions = games['chessy']['players'][player_id]['moves']\n",
    "    \n",
    "    actions = actions[idx]\n",
    "    \n",
    "    #action_diff = 4 - len(actions)\n",
    "    \n",
    "    #for i in range(action_diff):\n",
    "    #    actions.append((0,0))\n",
    "    \n",
    "    piece_num_id = numeric_names[piece]\n",
    "    \n",
    "    piece_bin_id = '{0:06b}'.format(piece_num_id + 17)\n",
    "    \n",
    "    actions_ = []\n",
    "    \n",
    "    for action in actions:\n",
    "        action_value_  = (8*action[0] + action[1] + 17)\n",
    "        action_value   = '{0:06b}'.format(action_value_)\n",
    "        actions_.append(action_value)\n",
    "        \n",
    "        piece_move_bin = (str(piece_bin_id)+str(action_value))\n",
    "        \n",
    "        actions_array.append(piece_move_bin)\n",
    "        \n",
    "        sparse_action  = str(piece_num_id)+\",\"+str(action[0])+ \",\" +str(action[1])\n",
    "        \n",
    "        action_sparse.append(sparse_action)\n",
    "        \n",
    "        sparse_action_dict[sparse_action] = piece_move_bin\n",
    "    \n",
    "    #print(piece_num_id, \"\\t\",piece_bin_id, \"\\t\", action_sparse,  \"\\t\", actions, \"\\t\", actions_)\n",
    "    \n",
    "    Pieces_detail[piece_num_id] = {\n",
    "        'piece_num_id':piece_num_id,\n",
    "        'piece_bin_id':piece_bin_id,\n",
    "        'action_sparse':action_sparse,\n",
    "        'actions_verbose': actions,\n",
    "        'actions_bin': actions_\n",
    "       }\n",
    "    \n",
    "action_ids = np.arange(0,len(sparse_action_dict.keys()),1)\n",
    "#print(action_ids)\n",
    "\n",
    "\n",
    "action_id_dict = {y:x for x,y in zip(action_ids,sparse_action_dict.keys())}\n",
    "print(action_id_dict) \n",
    "\n",
    "id_action_dict = {x:y for x,y in zip(action_ids,sparse_action_dict.keys())}\n",
    "print(id_action_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting args.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile args.py\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from numeric_names import numeric_names\n",
    "\n",
    "args = { \n",
    "    \"BUFFER_SIZE\":int(1e6),\n",
    "    \"BATCH_SIZE\":1024,  \n",
    "    \"GAMMA\":0.99,\n",
    "    \"TAU\":2e-3,\n",
    "    \"LR_ACTOR\":1e-3,\n",
    "    \"LR_CRITIC\":1.1e-3,\n",
    "    \"WEIGHT_DECAY\":0.0001,\n",
    "    \"UPDATE_EVERY\":5,\n",
    "    \"EXPLORE_NOISE\":0.05,\n",
    "    \"FC1_UNITS\":1024,\n",
    "    \"FC2_UNITS\":10240,\n",
    "    \"FC3_UNITS\":1024,\n",
    "    \"seed\":0,\n",
    "    \"state_size\":384,\n",
    "    \"action_size\":88,\n",
    "    \"action_size_binary\":12,\n",
    "    \"num_agents\":2,\n",
    "    \"device\":torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cuda:0\"),\n",
    "    'mcritic_path':'/home/ubuntu/chessy/checkpoint_mCritic.pth',\n",
    "    'agent_p0_path':'/home/ubuntu/chessy/checkpoint_p0.pth',\n",
    "    'agent_p1_path':'/home/ubuntu/chessy/checkpoint_p1.pth',\n",
    "    'action_id_dict': {'1,1,0': 0, '2,1,-2': 1, '2,1,2': 2, '2,2,-1': 3, '2,2,1': 4, '3,1,-1': 5, '3,1,1': 6, '4,1,-1': 7, '4,1,0': 8, '4,1,1': 9, '5,1,-1': 10, '5,1,0': 11, '5,1,1': 12, '6,1,-1': 13, '6,1,1': 14, '7,1,-2': 15, '7,1,2': 16, '7,2,-1': 17, '7,2,1': 18, '8,1,0': 19, '9,1,0': 20, '9,1,-1': 21, '9,1,1': 22, '10,1,0': 23, '10,1,-1': 24, '10,1,1': 25, '11,1,0': 26, '11,1,-1': 27, '11,1,1': 28, '12,1,0': 29, '12,1,-1': 30, '12,1,1': 31, '13,1,0': 32, '13,1,-1': 33, '13,1,1': 34, '14,1,0': 35, '14,1,-1': 36, '14,1,1': 37, '15,1,0': 38, '15,1,-1': 39, '15,1,1': 40, '16,1,0': 41, '16,1,-1': 42, '16,1,1': 43, '-16,-1,0': 44, '-16,-1,-1': 45, '-16,-1,1': 46, '-15,-1,0': 47, '-15,-1,-1': 48, '-15,-1,1': 49, '-14,-1,0': 50, '-14,-1,-1': 51, '-14,-1,1': 52, '-13,-1,0': 53, '-13,-1,-1': 54, '-13,-1,1': 55, '-12,-1,0': 56, '-12,-1,-1': 57, '-12,-1,1': 58, '-11,-1,0': 59, '-11,-1,-1': 60, '-11,-1,1': 61, '-10,-1,0': 62, '-10,-1,-1': 63, '-10,-1,1': 64, '-9,-1,0': 65, '-9,-1,-1': 66, '-9,-1,1': 67, '-8,-1,0': 68, '-7,-1,-2': 69, '-7,-1,2': 70, '-7,-2,-1': 71, '-7,-2,1': 72, '-6,-1,-1': 73, '-6,-1,1': 74, '-5,-1,-1': 75, '-5,-1,0': 76, '-5,-1,1': 77, '-4,-1,-1': 78, '-4,-1,0': 79, '-4,-1,1': 80, '-3,-1,-1': 81, '-3,-1,1': 82, '-2,-1,-2': 83, '-2,-1,2': 84, '-2,-2,-1': 85, '-2,-2,1': 86, '-1,-1,0': 87},\n",
    "    'id_action_dict': {0: '1,1,0', 1: '2,1,-2', 2: '2,1,2', 3: '2,2,-1', 4: '2,2,1', 5: '3,1,-1', 6: '3,1,1', 7: '4,1,-1', 8: '4,1,0', 9: '4,1,1', 10: '5,1,-1', 11: '5,1,0', 12: '5,1,1', 13: '6,1,-1', 14: '6,1,1', 15: '7,1,-2', 16: '7,1,2', 17: '7,2,-1', 18: '7,2,1', 19: '8,1,0', 20: '9,1,0', 21: '9,1,-1', 22: '9,1,1', 23: '10,1,0', 24: '10,1,-1', 25: '10,1,1', 26: '11,1,0', 27: '11,1,-1', 28: '11,1,1', 29: '12,1,0', 30: '12,1,-1', 31: '12,1,1', 32: '13,1,0', 33: '13,1,-1', 34: '13,1,1', 35: '14,1,0', 36: '14,1,-1', 37: '14,1,1', 38: '15,1,0', 39: '15,1,-1', 40: '15,1,1', 41: '16,1,0', 42: '16,1,-1', 43: '16,1,1', 44: '-16,-1,0', 45: '-16,-1,-1', 46: '-16,-1,1', 47: '-15,-1,0', 48: '-15,-1,-1', 49: '-15,-1,1', 50: '-14,-1,0', 51: '-14,-1,-1', 52: '-14,-1,1', 53: '-13,-1,0', 54: '-13,-1,-1', 55: '-13,-1,1', 56: '-12,-1,0', 57: '-12,-1,-1', 58: '-12,-1,1', 59: '-11,-1,0', 60: '-11,-1,-1', 61: '-11,-1,1', 62: '-10,-1,0', 63: '-10,-1,-1', 64: '-10,-1,1', 65: '-9,-1,0', 66: '-9,-1,-1', 67: '-9,-1,1', 68: '-8,-1,0', 69: '-7,-1,-2', 70: '-7,-1,2', 71: '-7,-2,-1', 72: '-7,-2,1', 73: '-6,-1,-1', 74: '-6,-1,1', 75: '-5,-1,-1', 76: '-5,-1,0', 77: '-5,-1,1', 78: '-4,-1,-1', 79: '-4,-1,0', 80: '-4,-1,1', 81: '-3,-1,-1', 82: '-3,-1,1', 83: '-2,-1,-2', 84: '-2,-1,2', 85: '-2,-2,-1', 86: '-2,-2,1', 87: '-1,-1,0'},\n",
    "    'numeric_names' : numeric_names,\n",
    "    'initial_state'  : \"010010010011010100010101010110010111011000011001011010011011011100011101011110011111100000100001000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001000010000011000100000101000110000111001000001001001010001011001100001101001110001111010000\",\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sparse_action_dict.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile sparse_action_dict.py\n",
    "\n",
    "sparse_action_dict = {'1,1,0':'010010011001','2,1,-2':'010011010111','2,1,2':'010011011011','2,2,-1':'010011100000','2,2,1':'010011100010','3,1,-1':'010100011000','3,1,1':'010100011010','4,1,-1':'010101011000','4,1,0':'010101011001','4,1,1':'010101011010','5,1,-1':'010110011000','5,1,0':'010110011001','5,1,1':'010110011010','6,1,-1':'010111011000','6,1,1':'010111011010','7,1,-2':'011000010111','7,1,2':'011000011011','7,2,-1':'011000100000','7,2,1':'011000100010','8,1,0':'011001011001','9,1,0':'011010011001','9,1,-1':'011010011000','9,1,1':'011010011010','10,1,0':'011011011001','10,1,-1':'011011011000','10,1,1':'011011011010','11,1,0':'011100011001','11,1,-1':'011100011000','11,1,1':'011100011010','12,1,0':'011101011001','12,1,-1':'011101011000','12,1,1':'011101011010','13,1,0':'011110011001','13,1,-1':'011110011000','13,1,1':'011110011010','14,1,0':'011111011001','14,1,-1':'011111011000','14,1,1':'011111011010','15,1,0':'100000011001','15,1,-1':'100000011000','15,1,1':'100000011010','16,1,0':'100001011001','16,1,-1':'100001011000','16,1,1':'100001011010','-16,-1,0':'000001001001','-16,-1,-1':'000001001000','-16,-1,1':'000001001010','-15,-1,0':'000010001001','-15,-1,-1':'000010001000','-15,-1,1':'000010001010','-14,-1,0':'000011001001','-14,-1,-1':'000011001000','-14,-1,1':'000011001010','-13,-1,0':'000100001001','-13,-1,-1':'000100001000','-13,-1,1':'000100001010','-12,-1,0':'000101001001','-12,-1,-1':'000101001000','-12,-1,1':'000101001010','-11,-1,0':'000110001001','-11,-1,-1':'000110001000','-11,-1,1':'000110001010','-10,-1,0':'000111001001','-10,-1,-1':'000111001000','-10,-1,1':'000111001010','-9,-1,0':'001000001001','-9,-1,-1':'001000001000','-9,-1,1':'001000001010','-8,-1,0':'001001001001','-7,-1,-2':'001010000111','-7,-1,2':'001010001011','-7,-2,-1':'001010000000','-7,-2,1':'001010000010','-6,-1,-1':'001011001000','-6,-1,1':'001011001010','-5,-1,-1':'001100001000','-5,-1,0':'001100001001','-5,-1,1':'001100001010','-4,-1,-1':'001101001000','-4,-1,0':'001101001001','-4,-1,1':'001101001010','-3,-1,-1':'001110001000','-3,-1,1':'001110001010','-2,-1,-2':'001111000111','-2,-1,2':'001111001011','-2,-2,-1':'001111000000','-2,-2,1':'001111000010','-1,-1,0':'010000001001'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pieces = {\n",
    "    'Pawn':(\"w_P\",\"b_P\"),\n",
    "    'Knight':(\"w_K\",\"b_K\"),\n",
    "    'King':(\"w__K\",\"b__K\"),\n",
    "    'Queen':(\"w__Q\",\"b__Q\"),\n",
    "    'Bishop':(\"w_B\",\"b_B\"),\n",
    "    'Rook':(\"w_R\",\"b_R\"),\n",
    "}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "  def getBin(num):\n",
    "        if int(num) != 0:\n",
    "            return \"{0:{fill}6b}\".format(int(num)+17, fill='0')\n",
    "        else:\n",
    "            return \"{0:{fill}6b}\".format(0, fill='0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sparse_action_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_moves   = 0\n",
    "policy_moves = 0\n",
    "random_moves = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFunc(piece):\n",
    "    def piece_func():\n",
    "        return piece\n",
    "    return piece_func()\n",
    "\n",
    "def Bishop():\n",
    "    return getFunc(\"Bishop\")\n",
    "\n",
    "def Pawn():\n",
    "    return getFunc(\"Pawn\")\n",
    "\n",
    "def King():\n",
    "    return getFunc(\"King\")\n",
    "\n",
    "def Queen():\n",
    "    return getFunc(\"Queen\")\n",
    "\n",
    "def Knight():\n",
    "    return getFunc(\"Knight\")\n",
    "\n",
    "def Rook():\n",
    "    return getFunc(\"Rook\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pawn'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pawn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Incorrect_Input_error(Exception):\n",
    "  \"\"\"Generic input error handler: raised in the case that any of the user inputed data is incorrect\"\"\"\n",
    "  pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp0  = None\n",
    "temp1  = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from args import args\n",
    "from sparse_action_dict import sparse_action_dict\n",
    "from numeric_names import numeric_names\n",
    "\n",
    "id_names = {value:key for key,value in numeric_names.items()}\n",
    "names    = {value: key for key in Pieces for value in Pieces[key]}\n",
    "\n",
    "stats_rewards_list = []\n",
    "\n",
    "def run_trial(user_input, env, mCritic):\n",
    "    global temp0\n",
    "    global temp1\n",
    "    global cycle\n",
    "    global scores\n",
    "    for j in range(user_input.num_sides):\n",
    "        team_name = \"team_\" + str(j)\n",
    "        team_name = Team(user_input.game, user_input.teams[j][\"team_name\"], j,user_input.teams[j][\"skill\"] / 10, user_input.teams[j][\"strategy\"])\n",
    "\n",
    "        env.insert_team(team_name)\n",
    "            \n",
    "    env.not_deadlocked  = True\n",
    "    env.states.append(args['initial_state'])\n",
    "    time_step    = 0\n",
    "        \n",
    "    total_reward = 0\n",
    "        \n",
    "    while env.not_deadlocked:\n",
    "         \n",
    "        curr_board_ids = {value:key for key,value in env.board.items()}\n",
    "        state   = env.state \n",
    "        state   = np.array(list(map(int, state))).astype(np.float32)\n",
    "        \n",
    "        #state_prior_tensor = torch.IntTensor(state_prior_bin).to(device)\n",
    "        action_ = agent_p0.act(state)\n",
    "        \n",
    "\n",
    "        #Determine feasible moves for each team:\n",
    "        feasible_moves     = []\n",
    "        feasible_moves_0   = env.get_feasible_moves(env.team[0])\n",
    "        feasible_moves_1   = env.get_feasible_moves(env.team[1])\n",
    "        [feasible_moves.append(x) for x in feasible_moves_0]\n",
    "        [feasible_moves.append(x) for x in feasible_moves_1]\n",
    "        \n",
    "        f_moves   = set([int(x) for x in [action_id_dict[str((args['numeric_names'][env.board[curr_pos]],move)).replace(\"(\",\"\").replace(\")\",\"\").replace(\" \",\"\")] for name, move, curr_pos, new_pos in feasible_moves]])\n",
    "        \n",
    "        #f_moves  = set(np.sort(f_moves, axis=-1, kind='quicksort', order=None))\n",
    "        \n",
    "        action_   = [v if k in f_moves else 0 for k,v in enumerate(action_)]\n",
    "\n",
    "        mid_point        = int((args['action_size']+1)/2)\n",
    "\n",
    "        action_idx_0     = np.argmax(action_[:mid_point])\n",
    "        action_idx_1     = np.argmax(action_[mid_point:]) + mid_point\n",
    "\n",
    "        action_sparse_0  = id_action_dict[action_idx_0]\n",
    "        action_sparse_1  = id_action_dict[action_idx_1]\n",
    "        #action_verbose_0 = (curr_board_ids[action_sparse_0[0]],action_sparse_0[1:])\n",
    "        \n",
    "        action_one_hot   = np.zeros(args['action_size'])\n",
    "        \n",
    "        action_one_hot[action_idx_0]   = 1\n",
    "        action_one_hot[action_idx_1]   = 1\n",
    "        \n",
    "        env.best_moves_sparse          = [action_sparse_0,action_sparse_1]\n",
    "        \n",
    "        \n",
    "        #############################################\n",
    "        #  SEPARATE OUT INTO A STANDALONE FUNCTION  #\n",
    "        #############################################\n",
    "        \n",
    "        \n",
    "        def get_verbose_action(sp_action,i):\n",
    "\n",
    "            act      = sp_action.split(\",\")\n",
    "            name     = id_names[int(act[0])]\n",
    "\n",
    "            curr_pos = curr_board_ids[name]\n",
    "            next_pos = zip(curr_pos,action)\n",
    "\n",
    "            move     = tuple([int(x) for x in act[1:]])\n",
    "\n",
    "            next_pos = tuple(sum(tuples) for tuples in zip(curr_pos,move))\n",
    "            \n",
    "            player   = env.team[i].players[name]\n",
    "                \n",
    "            moves    = [player,move, curr_pos,next_pos]\n",
    "            \n",
    "            return moves\n",
    "\n",
    "        \n",
    "        #############################################\n",
    "        # \n",
    "        #############################################\n",
    "        \n",
    "        \n",
    "        env.best_moves_verbose         = [get_verbose_action(action_sparse_0,0),get_verbose_action(action_sparse_1,1)]\n",
    "        \n",
    "        next_state, reward, done, info = env.step(cycle,user_input,args)\n",
    "        \n",
    "        next_state                     = np.array(list(map(int, env.state))).astype(np.float32)\n",
    "        \n",
    "        agent_p0.step(state, action_one_hot, int(reward), next_state, done, mCritic)\n",
    "        \n",
    "        time_step                      += 1\n",
    "        \n",
    "        total_reward                   += reward\n",
    "    \n",
    "    \n",
    "    result_agent = env.last_reward\n",
    "    \n",
    "    result_environment = None\n",
    "    \n",
    "    if result_agent == 1:\n",
    "        result_environment  = -1\n",
    "    elif result_agent == -1:\n",
    "        result_environment  = 1\n",
    "    else:\n",
    "        result_environment  = 0\n",
    "    \n",
    "    scores.append((cycle, info[0],info[1],result_agent, result_environment))\n",
    "    \n",
    "    stats_rewards_list.append((cycle, total_reward, time_step))\n",
    "    \n",
    "    results_agent = [r_a for c, i0, i1, r_a, r_e in scores]\n",
    "    results_env   = [r_e for c, i0, i1, r_a, r_e in scores]\n",
    "    \n",
    "    if time_step > 100 and cycle % 10 == 0:\n",
    "        print('Episode: {}'.format(cycle),\n",
    "        'Timestep: {}'.format(cycle),\n",
    "        'Total reward: {:.1f}'.format(np.mean(stats_rewards_list[-10:],  axis=0)[1]),\n",
    "        'Episode length: {:.1f}'.format(np.mean(stats_rewards_list[-10:],axis=0)[2]),\n",
    "        'Results Agent: {}'.format(np.mean(results_agent[-10:])),\n",
    "        'Results Environment:{}'.format(np.mean(results_env[-10:])),\n",
    "        'mCriticLoss: {:.4f}'.format(agent_p0.mCriticLoss),\n",
    "        'actorLoss: {:.4f}'.format(agent_p0.actorLoss))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def run_trials(user_input):\n",
    "    \"\"\" Runs the num_trials \"\"\"\n",
    "    global cycle\n",
    "    global HISTORY_FILE\n",
    "    global SUMMARY_FILE\n",
    "    global env\n",
    "    \n",
    "    print(\"==============================RUN_TRIALS==================================\")\n",
    "    \n",
    "    t = time.localtime()\n",
    "    timestamp = time.strftime('%b_%d_%Y_%H%M', t)\n",
    "    num_trials = user_input.num_trials\n",
    "    num_sides = user_input.num_sides\n",
    "    \n",
    "    SUMMARY_FILE = (\"/data_data/reinforcement_learning/results/summary_file.tsv\")\n",
    "\n",
    "    HISTORY_FILE = (\"/data_data/reinforcement_learning/results/history_file_\" + str(num_trials) + \"_trials_\" + str(num_sides) + \"_sides_\" + str(timestamp))\n",
    "    \n",
    "    \"\"\" Clear output file \"\"\"\n",
    "    \n",
    "    with open(HISTORY_FILE, \"w\") as history_file:\n",
    "        history_file.write(\"\\n\")\n",
    "        \n",
    "        \n",
    "    for i in range(num_trials):\n",
    "        \n",
    "        sides = [x for x in range(num_sides)]\n",
    "        \n",
    "        env = Game(user_input.game, 8, sides, user_input.display_board_positions)\n",
    "\n",
    "        run_trial(user_input,env, mCritic)\n",
    "\n",
    "        cycle += 1\n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent import Agent\n",
    "from model import ActorNetwork, CriticNetwork, MCritic\n",
    "from replaybuffer import ReplayBuffer\n",
    "from args import args\n",
    "\n",
    "mCritic       =  MCritic(args['state_size'],args['action_size'])\n",
    "agent_p0      =  Agent(args['state_size'],args['action_size'], 0)\n",
    "agent_p1      =  Agent(args['state_size'],args['action_size'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CriticNetwork(\n",
      "  (fc1): Linear(in_features=472, out_features=1024, bias=True)\n",
      "  (fc2): Linear(in_features=1024, out_features=10240, bias=True)\n",
      "  (fc3): Linear(in_features=10240, out_features=1024, bias=True)\n",
      "  (fc4): Linear(in_features=1024, out_features=1, bias=True)\n",
      ")\n",
      "ActorNetwork(\n",
      "  (fc1): Linear(in_features=384, out_features=1024, bias=True)\n",
      "  (fc2): Linear(in_features=1024, out_features=10240, bias=True)\n",
      "  (fc3): Linear(in_features=10240, out_features=1024, bias=True)\n",
      "  (fc4): Linear(in_features=1024, out_features=88, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(mCritic.network)\n",
    "print(agent_p0.actor_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select a game: ['chessy' or 'checkers']: chessy\n",
      "select number of teams:  [0, 1 or 2] 2\n",
      "Choose a name for this team [e.g. 'blue_team' or 'green_team']: Agent\n",
      "Choose a color for team_2 [e.g. 'blue': green\n",
      "Please enter team's skill_level [1 = Novice, 10 = expert]: 10\n",
      "Please enter team's strategy [0 = 'cooperative', 1 = 'competitive']: 1\n",
      "Choose a name for this team [e.g. 'blue_team' or 'green_team']: Environment\n",
      "Choose a color for team_2 [e.g. 'blue': red\n",
      "Please enter team's skill_level [1 = Novice, 10 = expert]: 1\n",
      "Please enter team's strategy [0 = 'cooperative', 1 = 'competitive']: 1\n",
      "How many trials would you like to run? [1 - 1,000,000] 1000\n",
      "Do you want to see the board positions in realtime? [ 'Yes' or 'No' ]no\n",
      "==============================RUN_TRIALS==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/chessy/model.py:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(self.fc4(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results_agent:\n",
      "[0]\n",
      "\n",
      "Results_env:\n",
      "[0]\n",
      "\n",
      "mCritic_loss:\t0\n",
      "\n",
      "Actor_loss:\t0\n",
      "\n",
      "===========================================\n",
      "Episode:      0 Timestep:           0 Total reward:   -136.0 Episode length: 137.0 Results Agent:      0.0 Results Environment:0.0 mCriticLoss:    0.0000 actorLoss:      0.0000\n",
      "Results_agent:\n",
      "[0, 0]\n",
      "\n",
      "Results_env:\n",
      "[0, 0]\n",
      "\n",
      "mCritic_loss:\t0\n",
      "\n",
      "Actor_loss:\t0\n",
      "\n",
      "===========================================\n",
      "Results_agent:\n",
      "[0, 0, 0]\n",
      "\n",
      "Results_env:\n",
      "[0, 0, 0]\n",
      "\n",
      "mCritic_loss:\t0\n",
      "\n",
      "Actor_loss:\t0\n",
      "\n",
      "===========================================\n",
      "Results_agent:\n",
      "[0, 0, 0, 0]\n",
      "\n",
      "Results_env:\n",
      "[0, 0, 0, 0]\n",
      "\n",
      "mCritic_loss:\t0\n",
      "\n",
      "Actor_loss:\t0\n",
      "\n",
      "===========================================\n",
      "Results_agent:\n",
      "[0, 0, 0, 0, 0]\n",
      "\n",
      "Results_env:\n",
      "[0, 0, 0, 0, 0]\n",
      "\n",
      "mCritic_loss:\t0\n",
      "\n",
      "Actor_loss:\t0\n",
      "\n",
      "===========================================\n",
      "Results_agent:\n",
      "[0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Results_env:\n",
      "[0, 0, 0, 0, 0, 0]\n",
      "\n",
      "mCritic_loss:\t0\n",
      "\n",
      "Actor_loss:\t0\n",
      "\n",
      "===========================================\n",
      "Results_agent:\n",
      "[0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Results_env:\n",
      "[0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "mCritic_loss:\t0\n",
      "\n",
      "Actor_loss:\t0\n",
      "\n",
      "===========================================\n",
      "Results_agent:\n",
      "[0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Results_env:\n",
      "[0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "mCritic_loss:\t0.001486388617195189\n",
      "\n",
      "Actor_loss:\t0.9700168967247009\n",
      "\n",
      "===========================================\n",
      "Results_agent:\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Results_env:\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "mCritic_loss:\t0.0006195497117005289\n",
      "\n",
      "Actor_loss:\t0.9847580790519714\n",
      "\n",
      "===========================================\n",
      "Results_agent:\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Results_env:\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "mCritic_loss:\t5.6651391787454486e-05\n",
      "\n",
      "Actor_loss:\t0.9942628145217896\n",
      "\n",
      "===========================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-713fef06f20b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mHISTORY_FILE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mrun_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mplot_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-0c937b98033c>\u001b[0m in \u001b[0;36mrun_trials\u001b[0;34m(user_input)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_board_positions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmCritic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mcycle\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-8b0aed6a52ea>\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(user_input, env, mCritic)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m#state_prior_tensor = torch.IntTensor(state_prior_bin).to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0maction_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent_p0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/chessy/agent.py\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, current_state)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0minput_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from agent import Agent\n",
    "from model import ActorNetwork, CriticNetwork, MCritic\n",
    "from replaybuffer import ReplayBuffer\n",
    "from plotutils import plot_results\n",
    "\n",
    "from games  import games\n",
    "from games import games\n",
    "from game   import Game\n",
    "from player import Player_Template\n",
    "from team   import Team\n",
    "from userinput import userInput\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    global cycle\n",
    "    global HISTORY_FILE\n",
    "    user_input = userInput()\n",
    "    run_trials(user_input)\n",
    "    plot_results(user_input)\n",
    "\n",
    "#main()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
