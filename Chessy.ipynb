{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "\n",
    "import ipykernel\n",
    "import pandas as pd\n",
    "\n",
    "#pd.set_option('display.height', 1000)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', 800)\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "pd.set_option('expand_frame_repr', True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import matplotlib.pyplot as plot\n",
    "import numpy as np\n",
    "import os\n",
    "import jsonlines\n",
    "import ast\n",
    "import time, os, fnmatch, shutil\n",
    "from collections import defaultdict\n",
    "import matplotlib\n",
    "import requests\n",
    "\n",
    "import math\n",
    "import random\n",
    "import copy\n",
    "\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from games  import games\n",
    "from games import games\n",
    "from game   import Game\n",
    "from player import Player_Template\n",
    "from team   import Team\n",
    "from userinput import userInput\n",
    "\n",
    "\n",
    "\n",
    "HISTORY_FILE = None\n",
    "\n",
    "summary_dict = {\"losses\":0,\"wins\":0,\"draws\":0}\n",
    "\n",
    "cycle = 0\n",
    "\n",
    "actions = [[], []]\n",
    "rewards = [[], []]\n",
    "history = {\"cycle\": cycle, \"actions\": actions, \"rewards\": rewards, \"value\": 0}\n",
    "\n",
    "score_board = {}\n",
    "#step_action_dict = defaultdict()\n",
    "#step_action_dict['random_moves'] = defaultdict()\n",
    "#step_action_dict['policy_moves'] = defaultdict()\n",
    "\n",
    "numeric_names = {'w_R0': 1, 'w_K0': 2, 'w_B0': 3, 'w__K': 4, 'w__Q': 5, 'w_B1': 6, 'w_K1': 7, 'w_R1': 8, 'w_P0': 9, 'w_P1':\n",
    " 10, 'w_P2': 11, 'w_P3': 12, 'w_P4': 13, 'w_P5': 14, 'w_P6': 15, 'w_P7': 16, 'b_P0': -16, 'b_P1': -15, 'b_P2': -14, 'b_P3':\n",
    " -13, 'b_P4': -12, 'b_P5': -11, 'b_P6': -10, 'b_P7': -9, 'b_R0': -8, 'b_K0': -7, 'b_B0': -6, 'b__K': -5, 'b__Q': -4, 'b_B1'\n",
    ": -3, 'b_K1': -2, 'b_R1': -1}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sparse_action_dict.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile sparse_action_dict.py\n",
    "\n",
    "sparse_action_dict = {'1,1,0':'010010011001','2,1,-2':'010011010111','2,1,2':'010011011011','2,2,-1':'010011100000','2,2,1':'010011100010','3,1,-1':'010100011000','3,1,1':'010100011010','4,1,-1':'010101011000','4,1,0':'010101011001','4,1,1':'010101011010','5,1,-1':'010110011000','5,1,0':'010110011001','5,1,1':'010110011010','6,1,-1':'010111011000','6,1,1':'010111011010','7,1,-2':'011000010111','7,1,2':'011000011011','7,2,-1':'011000100000','7,2,1':'011000100010','8,1,0':'011001011001','9,1,0':'011010011001','9,1,-1':'011010011000','9,1,1':'011010011010','10,1,0':'011011011001','10,1,-1':'011011011000','10,1,1':'011011011010','11,1,0':'011100011001','11,1,-1':'011100011000','11,1,1':'011100011010','12,1,0':'011101011001','12,1,-1':'011101011000','12,1,1':'011101011010','13,1,0':'011110011001','13,1,-1':'011110011000','13,1,1':'011110011010','14,1,0':'011111011001','14,1,-1':'011111011000','14,1,1':'011111011010','15,1,0':'100000011001','15,1,-1':'100000011000','15,1,1':'100000011010','16,1,0':'100001011001','16,1,-1':'100001011000','16,1,1':'100001011010','-16,-1,0':'000001001001','-16,-1,-1':'000001001000','-16,-1,1':'000001001010','-15,-1,0':'000010001001','-15,-1,-1':'000010001000','-15,-1,1':'000010001010','-14,-1,0':'000011001001','-14,-1,-1':'000011001000','-14,-1,1':'000011001010','-13,-1,0':'000100001001','-13,-1,-1':'000100001000','-13,-1,1':'000100001010','-12,-1,0':'000101001001','-12,-1,-1':'000101001000','-12,-1,1':'000101001010','-11,-1,0':'000110001001','-11,-1,-1':'000110001000','-11,-1,1':'000110001010','-10,-1,0':'000111001001','-10,-1,-1':'000111001000','-10,-1,1':'000111001010','-9,-1,0':'001000001001','-9,-1,-1':'001000001000','-9,-1,1':'001000001010','-8,-1,0':'001001001001','-7,-1,-2':'001010000111','-7,-1,2':'001010001011','-7,-2,-1':'001010000000','-7,-2,1':'001010000010','-6,-1,-1':'001011001000','-6,-1,1':'001011001010','-5,-1,-1':'001100001000','-5,-1,0':'001100001001','-5,-1,1':'001100001010','-4,-1,-1':'001101001000','-4,-1,0':'001101001001','-4,-1,1':'001101001010','-3,-1,-1':'001110001000','-3,-1,1':'001110001010','-2,-1,-2':'001111000111','-2,-1,2':'001111001011','-2,-2,-1':'001111000000','-2,-2,1':'001111000010','-1,-1,0':'010000001001'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device  = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cuda:0\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pieces = {\n",
    "    'Pawn':(\"w_P\",\"b_P\"),\n",
    "    'Knight':(\"w_K\",\"b_K\"),\n",
    "    'King':(\"w__K\",\"b__K\"),\n",
    "    'Queen':(\"w__Q\",\"b__Q\"),\n",
    "    'Bishop':(\"w_B\",\"b_B\"),\n",
    "    'Rook':(\"w_R\",\"b_R\"),\n",
    "}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "  def getBin(num):\n",
    "        if int(num) != 0:\n",
    "            return \"{0:{fill}6b}\".format(int(num)+17, fill='0')\n",
    "        else:\n",
    "            return \"{0:{fill}6b}\".format(0, fill='0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pieces_detail = defaultdict()\n",
    "actions_array = []\n",
    "sparse_action_dict = defaultdict()\n",
    "actions = []\n",
    "\n",
    "for piece in numeric_names.keys():\n",
    "    action_sparse = []\n",
    "    if piece[0] == 'w':\n",
    "        idx = 0\n",
    "    else:\n",
    "        idx = 1\n",
    "        \n",
    "    if piece[1:3] == '_R':\n",
    "        player_id = 'Rook'\n",
    "    elif piece[1:3] == '_K':\n",
    "        player_id = 'Knight'\n",
    "    elif piece[1:3] == '_B':\n",
    "        player_id = 'Bishop'\n",
    "    elif piece[1:3] == '_P':\n",
    "        player_id = 'Pawn'\n",
    "    elif piece[1:4] == '__K':\n",
    "        player_id = 'King'\n",
    "    elif piece[:3] == '__Q':\n",
    "        player_id = 'Queen'\n",
    "        \n",
    "    actions = games['chessy']['players'][player_id]['moves']\n",
    "    \n",
    "    actions = actions[idx]\n",
    "    \n",
    "    #action_diff = 4 - len(actions)\n",
    "    \n",
    "    #for i in range(action_diff):\n",
    "    #    actions.append((0,0))\n",
    "    \n",
    "    piece_num_id = numeric_names[piece]\n",
    "    \n",
    "    piece_bin_id = '{0:06b}'.format(piece_num_id + 17)\n",
    "    \n",
    "    actions_ = []\n",
    "    \n",
    "    for action in actions:\n",
    "        action_value_  = (8*action[0] + action[1] + 17)\n",
    "        action_value   = '{0:06b}'.format(action_value_)\n",
    "        actions_.append(action_value)\n",
    "        \n",
    "        piece_move_bin = (str(piece_bin_id)+str(action_value))\n",
    "        \n",
    "        actions_array.append(piece_move_bin)\n",
    "        \n",
    "        sparse_action  = str(piece_num_id)+\",\"+str(action[0])+ \",\" +str(action[1])\n",
    "        \n",
    "        action_sparse.append(sparse_action)\n",
    "        \n",
    "        sparse_action_dict[sparse_action] = piece_move_bin\n",
    "    \n",
    "    #print(piece_num_id, \"\\t\",piece_bin_id, \"\\t\", action_sparse,  \"\\t\", actions, \"\\t\", actions_)\n",
    "    \n",
    "    Pieces_detail[piece_num_id] = {\n",
    "        'piece_num_id':piece_num_id,\n",
    "        'piece_bin_id':piece_bin_id,\n",
    "        'action_sparse':action_sparse,\n",
    "        'actions_verbose': actions,\n",
    "        'actions_bin': actions_\n",
    "       }\n",
    "    \n",
    "action_ids = np.arange(0,len(sparse_action_dict.keys()),1)\n",
    "#action_ids\n",
    "\n",
    "action_id_dict = {y:x for x,y in zip(action_ids,sparse_action_dict.keys())}\n",
    "#action_id_dict \n",
    "\n",
    "id_action_dict = {x:y for x,y in zip(action_ids,sparse_action_dict.keys())}\n",
    "#id_action_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state =  \"010010010011010100010101010110010111011000011001011010011011011100011101011110011111100000100001000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001000010000011000100000101000110000111001000001001001010001011001100001101001110001111010000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = { \n",
    "    \"BUFFER_SIZE\":int(1e6),\n",
    "    \"BATCH_SIZE\":1024,  \n",
    "    \"GAMMA\":0.99,\n",
    "    \"TAU\":2e-3,\n",
    "    \"LR_ACTOR\":1e-3,\n",
    "    \"LR_CRITIC\":1.1e-3,\n",
    "    \"WEIGHT_DECAY\":0.0001,\n",
    "    \"UPDATE_EVERY\":5,\n",
    "    \"EXPLORE_NOISE\":0.05,\n",
    "    \"FC1_UNITS\":1024,\n",
    "    \"FC2_UNITS\":10240,\n",
    "    \"FC3_UNITS\":1024,\n",
    "    \"seed\":0,\n",
    "    \"state_size\":384,\n",
    "    \"action_size\":87,\n",
    "    \"num_agents\":2,\n",
    "    \"device\":device,\n",
    "    'mcritic_path':'/home/ubuntu/chessy/checkpoint_mCritic.pth',\n",
    "    'agent_p0_path':'/home/ubuntu/chessy/checkpoint_p0.pth',\n",
    "    'agent_p1_path':'/home/ubuntu/chessy/checkpoint_p1.pth',\n",
    "    'action_ids': action_ids,\n",
    "    'action_id_dict': action_id_dict,\n",
    "    'id_action_dict': id_action_dict,\n",
    "    'numeric_names' : numeric_names,\n",
    "    'initial_state'  : initial_state,\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sparse_action_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_moves   = 0\n",
    "policy_moves = 0\n",
    "random_moves = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFunc(piece):\n",
    "    def piece_func():\n",
    "        return piece\n",
    "    return piece_func()\n",
    "\n",
    "def Bishop():\n",
    "    return getFunc(\"Bishop\")\n",
    "\n",
    "def Pawn():\n",
    "    return getFunc(\"Pawn\")\n",
    "\n",
    "def King():\n",
    "    return getFunc(\"King\")\n",
    "\n",
    "def Queen():\n",
    "    return getFunc(\"Queen\")\n",
    "\n",
    "def Knight():\n",
    "    return getFunc(\"Knight\")\n",
    "\n",
    "def Rook():\n",
    "    return getFunc(\"Rook\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Incorrect_Input_error(Exception):\n",
    "  \"\"\"Generic input error handler: raised in the case that any of the user inputed data is incorrect\"\"\"\n",
    "  pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trial(user_input, env, mCritic):\n",
    "    global cycle\n",
    "    global scores\n",
    "    for j in range(user_input.num_sides):\n",
    "        team_name = \"team_\" + str(j)\n",
    "        team_name = Team(user_input.game, user_input.teams[j][\"team_name\"], j,user_input.teams[j][\"skill\"] / 10, user_input.teams[j][\"strategy\"])\n",
    "\n",
    "        env.insert_team(team_name)\n",
    "            \n",
    "    env.not_deadlocked = True\n",
    "    env.states.append(initial_state)\n",
    "    time_step = 0\n",
    "        \n",
    "    while env.not_deadlocked:\n",
    "        #print(\"ENV.STATES[-1]:\\n{}\\n\".format(env.states[-1]))\n",
    "        state        = env.state \n",
    "        state    = np.array(list(map(int, state))).astype(np.float32)\n",
    "        \n",
    "        #state_prior_tensor = torch.IntTensor(state_prior_bin).to(device)\n",
    "        action             = agent_p0.act(state)\n",
    "        \n",
    "        action             = np.array([int(x) for x in list(args['id_action_dict'][np.argmax(action)].split(\",\"))]) \n",
    "        \n",
    "        next_state, reward, done, info = env.step(cycle,user_input,args)\n",
    "        \n",
    "        next_state         = np.array(list(map(int, env.state))).astype(np.float32)\n",
    "        \n",
    "        agent_p0.step(state, action, int(reward), next_state, done, mCritic)\n",
    "        \n",
    "        time_step += 1\n",
    "        \n",
    "    scores.append((cycle, info[0],info[1]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trials(user_input):\n",
    "    \"\"\" Runs the num_trials \"\"\"\n",
    "    global cycle\n",
    "    global HISTORY_FILE\n",
    "    global SUMMARY_FILE\n",
    "    global env\n",
    "    \n",
    "    print(\"==============================RUN_TRIALS==================================\")\n",
    "    \n",
    "    t = time.localtime()\n",
    "    timestamp = time.strftime('%b_%d_%Y_%H%M', t)\n",
    "    num_trials = user_input.num_trials\n",
    "    num_sides = user_input.num_sides\n",
    "    \n",
    "    SUMMARY_FILE = (\"/data_data/reinforcement_learning/results/summary_file.tsv\")\n",
    "\n",
    "    HISTORY_FILE = (\"/data_data/reinforcement_learning/results/history_file_\" + str(num_trials) + \"_trials_\" + str(num_sides) + \"_sides_\" + str(timestamp))\n",
    "    \n",
    "    \"\"\" Clear output file \"\"\"\n",
    "    \n",
    "    with open(HISTORY_FILE, \"w\") as history_file:\n",
    "        history_file.write(\"\\n\")\n",
    "        \n",
    "        \n",
    "    for i in range(num_trials):\n",
    "        \n",
    "        sides = [x for x in range(num_sides)]\n",
    "        \n",
    "        env = Game(user_input.game, args, 8, sides, user_input.display_board_positions)\n",
    "\n",
    "        run_trial(user_input,env, mCritic)\n",
    "\n",
    "        cycle += 1\n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args['action_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent import Agent\n",
    "from model import ActorNetwork, CriticNetwork, MCritic\n",
    "from replaybuffer import ReplayBuffer\n",
    "\n",
    "mCritic       =  MCritic(args['state_size'],args['action_size'], args)\n",
    "agent_p0      =  Agent(args['state_size'],args['action_size'], 0,args)\n",
    "agent_p1      =  Agent(args['state_size'],args['action_size'], 1,args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CriticNetwork(\n",
      "  (fc1): Linear(in_features=471, out_features=1024, bias=True)\n",
      "  (fc2): Linear(in_features=1024, out_features=10240, bias=True)\n",
      "  (fc3): Linear(in_features=10240, out_features=1024, bias=True)\n",
      "  (fc4): Linear(in_features=1024, out_features=1, bias=True)\n",
      ")\n",
      "ActorNetwork(\n",
      "  (fc1): Linear(in_features=384, out_features=1024, bias=True)\n",
      "  (fc2): Linear(in_features=1024, out_features=10240, bias=True)\n",
      "  (fc3): Linear(in_features=10240, out_features=1024, bias=True)\n",
      "  (fc4): Linear(in_features=1024, out_features=87, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(mCritic.network)\n",
    "print(agent_p0.actor_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select a game: ['chessy' or 'checkers']: chessy\n",
      "select number of teams:  [0, 1 or 2] 2\n",
      "Choose a name for this team [e.g. 'blue_team' or 'green_team']: Agent\n",
      "Choose a color for team_2 [e.g. 'blue': green\n",
      "Please enter team's skill_level [1 = Novice, 10 = expert]: 10\n",
      "Please enter team's strategy [0 = 'cooperative', 1 = 'competitive']: 1\n",
      "Choose a name for this team [e.g. 'blue_team' or 'green_team']: Environment\n",
      "Choose a color for team_2 [e.g. 'blue': red\n",
      "Please enter team's skill_level [1 = Novice, 10 = expert]: 1\n",
      "Please enter team's strategy [0 = 'cooperative', 1 = 'competitive']: 1\n",
      "How many trials would you like to run? [1 - 1,000,000] 10000\n",
      "Do you want to see the board positions in realtime? [ 'Yes' or 'No' ]no\n",
      "==============================RUN_TRIALS==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/chessy/model.py:46: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(self.fc4(x))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [471 x 1024], m2: [471 x 1024] at /opt/conda/conda-bld/pytorch_1579040055865/work/aten/src/THC/generic/THCTensorMathBlas.cu:290",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-447162d2a4fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mHISTORY_FILE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mrun_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#main()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-fea2718e87bb>\u001b[0m in \u001b[0;36mrun_trials\u001b[0;34m(user_input)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_board_positions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmCritic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mcycle\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-60ad9cf9516e>\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(user_input, env, mCritic)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mnext_state\u001b[0m         \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0magent_p0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmCritic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mtime_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/chessy/agent.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, state, action, reward, next_state, done, mCritic)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'BATCH_SIZE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mexperiences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmCritic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/chessy/agent.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, experiences, mCritic)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;31m# Get predicted next-state actions and Q values from target models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mactions_next\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0mQ_targets_next\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmCritic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions_next\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;31m# Compute Q targets for current states (y_i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/chessy/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, state, action)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mstate\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0;31m#print(\"INPUT:\\n{}\\n\".format(input))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [471 x 1024], m2: [471 x 1024] at /opt/conda/conda-bld/pytorch_1579040055865/work/aten/src/THC/generic/THCTensorMathBlas.cu:290"
     ]
    }
   ],
   "source": [
    "\n",
    "from agent import Agent\n",
    "from model import ActorNetwork, CriticNetwork, MCritic\n",
    "from replaybuffer import ReplayBuffer\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    global cycle\n",
    "    global HISTORY_FILE\n",
    "    user_input = userInput()\n",
    "    run_trials(user_input)\n",
    "\n",
    "#main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = \"2,2,-1\"\n",
    "action.split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor(np.random.choice((0,1),87)).to(device)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.Tensor(np.random.choice((0,1),384)).to(device)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.view(x.size(0), -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat((x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
