{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "#pd.set_option('display.height', 1000)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', 800)\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "pd.set_option('expand_frame_repr', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sc.stop()\n",
    "    \n",
    "    spark.stop()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "APP_NAME = \"Policy Evaluation - Chessy II\"\n",
    "\n",
    "from pyspark import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "\n",
    "    \n",
    "sc = SparkContext(conf = SparkConf() \n",
    "                  .set(\"spark.driver.maxResultSize\", \"128g\") \n",
    "                  .set(\"spark.sql.execution.arrow.enabled\", \"true\") \n",
    "                  .set('spark.sql.broadcastTimeout', 1000) \n",
    "                  .set('spark.local.dir', '/data_data/session_length/spark_tmp/') \n",
    "                  .set('spark.driver.memory', '128G') \n",
    "                  .set(\"spark.executor.instances\", \"12\") \n",
    "                  .set(\"spark.executor.cores\", 12) \n",
    "                  .set(\"spark.executor.memory\", \"8G\")).getOrCreate()\n",
    "\n",
    "spark = SparkSession(sc)\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructField, StructType, StringType, LongType, DateType, DoubleType, IntegerType, ArrayType, BooleanType\n",
    "from pyspark.sql.functions import approx_count_distinct, countDistinct, count, mean, stddev_pop, min, max, lit, round, bround, pow, col, corr, lower, upper, avg, stddev, abs, log\n",
    "from pyspark.sql.functions import lit, trim, rtrim, rpad, trim, coalesce\n",
    "from pyspark.sql.functions import current_date, current_timestamp, date_add, date_sub, months_between, to_date\n",
    "from pyspark.sql.functions import udf, col, sum, from_json,lag, lead, monotonically_increasing_id, row_number, array, explode, desc\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import desc, dense_rank, rank, expr, split, regexp_replace\n",
    "\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import RFormula\n",
    "from pyspark.ml.classification import LogisticRegression, GBTClassifier, DecisionTreeClassifier, RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.regression import RandomForestRegressor, GBTRegressor\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -alrth /data_data/reinforcement_learning/results/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 5 /data_data/reinforcement_learning/results/history_file_1000000_trials_2_sides_Jun_15_2020_1334"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up schema for episode data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_to_import = \"/data_data/reinforcement_learning/results/history_file_1000000_trials_2_sides_Jun_15_2020_1334\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = file_to_import.split(\"/\")[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SARF = None\n",
    "def import_episode_data():\n",
    "    print(\"===============================================================================================================\")\n",
    "    print(\"====================================\"+ file_name + \"====================================================\")\n",
    "    print(\"===============================================================================================================\\n\\n\")\n",
    "    global SARF\n",
    "    DRLSchema = StructType([\\\n",
    "        StructField('episode',  IntegerType(), True),\\\n",
    "        StructField('step',     IntegerType(), True),\\\n",
    "        StructField('_state_prior',   StringType(),  True),\\\n",
    "        StructField('reward_',   IntegerType(), True),\\\n",
    "        StructField('action',   StringType(),  True),\\\n",
    "        StructField('action_verbose',   StringType(),  True),\\\n",
    "        StructField('action_size',        IntegerType(),    True),\\\n",
    "        StructField('done',        IntegerType(),    True)])  \n",
    "    \n",
    "    udf_lr_trim = udf(lambda str_arr:str_arr[1:-1], StringType())\n",
    "    \n",
    "    #SARF = spark.read.format('csv').schema(DRLSchema).option(\"sep\",\"\\t\").load(file_to_import).withColumn('_state_prior',udf_lr_trim('_state_prior_')).drop('_state_prior_').drop('a')\n",
    "    \n",
    "    cols = ['episode']\n",
    "\n",
    "    ww = Window.orderBy(cols)\n",
    "    \n",
    "    SARF = spark.read.format('com.databricks.spark.csv').schema(DRLSchema).option('delimiter', '\\t').option('mode', 'DROPMALFORMED').options(header='false', delimiter='\\t').load(file_to_import).withColumn(\"id\", row_number().over(ww)).na.drop(how=\"all\")\n",
    "    #SARF = SARF.selectExpr(\"cast(_c0 as int) as episode\", \"cast(_c1 as int) as step\",\"cast(_c2 as string) as _state_prior\", \"cast(_c3 as string) as reward_\", \"cast(_c4 as string) as action\", \"cast(_c5 as string) as action_verbose\",\"cast(_c6 as int) as action_size\",\"cast(_c7 as int) as done\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import episode data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_episode_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SARF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SARF.show(200,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SARF.groupBy('_state_prior').count().sort(desc(\"count\")).show(100,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SARF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create unique ID for each turn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Note: Agent moves are ODD numbered whereas Environment moves are EVEN numbered\n",
    "###### Here we add an index column (ID) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['episode','step']\n",
    "\n",
    "w = Window.orderBy(cols)\n",
    "\n",
    "#SARF_df_ = SARF.withColumn(\"id\", row_number().over(w))\n",
    "\n",
    "SARF_df_ = SARF.withColumn(\"id\", monotonically_increasing_id())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SARF_df_.show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SARF_df_.groupBy('_state_prior').count().sort(desc(\"count\")).show(100,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rownums = 10\n",
    "#SARF_df_.where(col('id')>SARF_df_.count()-rownums).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_step = Window.partitionBy('episode')\n",
    "\n",
    "getWinStatus = udf(lambda max_col:  1 if max_col == 20 else 0, IntegerType())\n",
    "\n",
    "SARF_df = SARF_df_.withColumn('win_status',getWinStatus(max(col('reward_')).over(w_step))).where('win_status == 1').drop('win_status')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#SARF_df.show(200, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SARF_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a column that captures BOTH Agent and Environment turns into a single row [SARS]\n",
    "#### Drop the odd rows (which only capture Agent moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SARF_df.registerTempTable(\"SARF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.sql(\"select * from SARF\").show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.sql(\"select count(*) from SARF\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a_df = spark.sql('select id,episode,turn,_state_prior,action,lead(_state_prior,3) over(partition by episode order by turn) as state_prime from SARF').show(150,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBin(num):\n",
    "    if int(num) != 0:\n",
    "        return \"{0:{fill}6b}\".format(int(num)+17, fill='0')\n",
    "    else:\n",
    "        return \"{0:{fill}6b}\".format(0, fill='0')\n",
    "  \n",
    "piece_value_dict_ = {\"0\":0, \"1\":5,\"2\":3,\"3\":3,\"4\":9,\"5\":20,\"6\":3,\"7\":3,\"8\":5,\"9\":1,\"10\":1,\"11\":1,\"12\":1,\"13\":1,\"14\":1,\"15\":1,\"16\":1,\"-16\":-1,\"-15\":-1,\"-14\":-1,\"-13\":-1,\"-12\":-1,\"-11\":-1,\"-10\":-1,\"-9\":-1,\"-8\":-5,\"-7\":-3,\"-6\":-3,\"-5\":-9,\"-4\":-20,\"-3\":-3,\"-2\":-3,\"-1\":-5}\n",
    "\n",
    "piece_value_dict = {k:getBin(v) for k,v in piece_value_dict_.items()}\n",
    "\n",
    "#piece_value_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state_ = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1]\n",
    "initial_state  = \"\".join([getBin(x) for x in initial_state_])\n",
    "initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_step = Window.partitionBy('episode').orderBy(col(\"id\"))\n",
    "\n",
    "\n",
    "\n",
    "SARF_env_step_df = SARF_df.withColumn('_state_prime',lead(col('_state_prior'),2,initial_state).over(w_step)).withColumn('state_prior', col('_state_prior')).drop('_state').withColumn('state_prime', col('_state_prime')).drop('_state_prime').drop('_state_prior').filter(SARF_df[\"step\"] % 2 == 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SARF_env_step_df.show(150,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check_lag_udf = udf(lambda a,b: a==b, BooleanType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SARF_test_lag_df = SARF_env_step_df.withColumn(\"lag_check\", check_lag_udf(col('state_prime'),col('state_prior')))\n",
    "#SARF_test_lag_df.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SARF_df_.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SARF_env_step_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SARF_env_step_df.where(\"state_prior == '010010010011010100010101010110010111011000011001011010011011011100011101011110011111100000100001000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001000010000011000100000101000110000111001000001001001010001011001100001101001110001111010000'\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SARF_df.where(\"_state_prior == '010010010011010100010101010110010111011000011001011010011011011100011101011110011111100000100001000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001000010000011000100000101000110000111001000001001001010001011001100001101001110001111010000'\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SARF_env_step_df.groupBy('state_prior').count().sort(desc(\"count\")).show(20,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SARF_df.groupBy('_state_prior').count().sort(desc(\"count\")).show(20,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Hyperparameters for MDPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discount rate\n",
    "gamma = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learning rate\n",
    "alpha = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate reward for each SAS transition using the SUM_Diffs of the respective States \n",
    "#### NOTE: Here we lookup player/piece actual values in a dictusing their board_ids  (16 -> 16)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_reward(reward_):\n",
    "    reward = reward_\n",
    "    if reward <= -1:\n",
    "        return -1\n",
    "    elif reward >= 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_normalized_reward = udf(lambda x: normalized_reward(x), IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SASR_df = SARF_env_step_df.withColumn('reward', get_normalized_reward(col('reward_'))).drop('reward_')\n",
    "SASR_df = SARF_env_step_df.withColumn('reward',col('reward_'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SASR_df.show(100,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SASR_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp_df = SASR_df.withColumn(\"event\", array(col('state_prior'),col('action'),col('reward'),col('action_verbose'),col('state_prime'),col('done'))).drop('state_prime').drop('state_prior').drop('action_verbose').drop('action').drop('step').drop('id').drop('reward').drop('reward_')\n",
    "#temp_df.show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  pyspark.sql import functions as F\n",
    "#temp_df_ = temp_df.groupBy(\"episode\").agg(F.collect_list(\"event\"))\n",
    "#temp_df_.show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp_df_.show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "byEpisode = Window.partitionBy('episode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_discounted_reward = udf(lambda reward, step, episode_length, discount: int(reward)*discount**(int((episode_length - step)/2)), DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SASR_discounted_rewards_df = SASR_df.withColumn('discounted_reward',get_discounted_reward(col('reward'),col('step'), max('step').over(byEpisode),lit(gamma)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SASR_discounted_rewards_df.show(150,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "byEpisode = Window.partitionBy('episode').orderBy(col('step'))\n",
    "\n",
    "get_state_value = udf(lambda reward, discounted_rewards: normalized_reward(reward) + discounted_rewards, DoubleType())\n",
    "\n",
    "SASR_cumsum_discounted_rewards_df = SASR_discounted_rewards_df.withColumn('value',get_state_value(col('reward'),col('discounted_reward')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##SASR_cumsum_discounted_rewards_df.show(200,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Average Value for a state V(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "State_Value_df = SASR_cumsum_discounted_rewards_df.groupBy('state_prior').agg(expr('avg(value) as state_value')).withColumnRenamed('state_prior','state') \n",
    "#State_Value_df.show(10,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Q(s,a) == State_Action Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "State_Action_Value_df = SASR_cumsum_discounted_rewards_df.groupBy(['state_prior','action','action_verbose','reward']).agg(expr('avg(value) as V_state_action'),expr('stddev_pop(value) as std_value'),expr('count(state_prior) as visits'))\n",
    "#State_Action_Value_df.show(10,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate T(s,a,s_) == State_Action_State' Transition Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "State_Action_State_df_ = SASR_cumsum_discounted_rewards_df.groupBy(['state_prior','action','action_verbose','state_prime','reward']).agg(expr('count(state_prime) as transitions'))\n",
    "#State_Action_State_df_.show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sas_window_spec = Window.partitionBy('state_prior')\n",
    "\n",
    "get_transition_frequency_udf = udf(lambda transitions, state_visits: 1.0 if transitions > state_visits else transitions/state_visits, DoubleType())\n",
    "\n",
    "State_Action_State_df = State_Action_State_df_.withColumn('state_visits', count('state_prior').over(sas_window_spec)).withColumn('trans_freq',get_transition_frequency_udf('transitions','state_visits') )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#State_Action_State_df.show(200,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Policy == P(s,a) for MDP modelling of Environment \n",
    "###### Assume agent would use equiprobable action selection or random selection from feasible actions to teleport to another state if it encounters an unknown state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#State_Value_df.show(200,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join state_value table with state_transition_matrix to create Policy_Calc_Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = State_Action_State_df.alias('t')\n",
    "s = State_Value_df.alias('s')\n",
    "join_condition = [ (s.state == t.state_prime) ]\n",
    "policy_calc_df_ = t.join(s, join_condition, 'inner').drop('state')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#policy_calc_df_.show(200,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#policy_calc_df_.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate Expected Value (trans_freq * state_value) for each SAS transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_expected_sas_value = udf(lambda alpha,gamma,reward,trans_freq,state_value: trans_freq*alpha*(reward + gamma*state_value),DoubleType())\n",
    "\n",
    "policy_calc_df = policy_calc_df_.withColumn('expected_value', get_expected_sas_value(lit(alpha),lit(gamma),col('reward'),col('trans_freq'), col('state_value')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#policy_calc_df.show(200, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#policy_calc_df.groupBy(['state_prior', 'action_verbose','trans_freq','expected_value','state_visits']).agg(expr('count(state_visits) as s_visits')).orderBy(desc('state_visits')).show(200, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#policy_calc_df.where('state_visits > 100').show(100,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#policy_calc_df.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_df = policy_calc_df.select('state_prior', 'expected_value',max('action_verbose').over(sas_window_spec).alias('policy'))\n",
    "#policy_df = policy_calc_df.select('state_prior', 'action_verbose', max('expected_value').over(sas_window_spec).alias('policy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#policy_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_prefix = '/data_data/reinforcement_learning/results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_file = os.path.join(dir_prefix,(file_name.split(\".\")[0] + \".json\"))\n",
    "#policy_file = '/data_data/reinforcement_learning/results/policy_file'\n",
    "!rm -rf {policy_file}\n",
    "policy_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_df.coalesce(1).dropDuplicates().write.format('json').save(policy_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = str(os.path.join(policy_file,\"part*\"))\n",
    "!ls {infile}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tail -n 5 {infile} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge/Append new policy to Combined Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_policy_df = spark.read.format(\"json\").option(\"mode\",\"FAILFAST\").option(\"inferschema\",\"true\").load(\"/data_data/reinforcement_learning/results/*.json/part-*.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined_policy_df.show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state1 = \"010010010011010100010101010110010111000000011001011010011011011100011101011110011111100000100001000000000000000000000000000000011000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000100000000000000000000000000000001000010000011000000000101000110000111001000001001001010001011001100001101001110001111010000|\"\n",
    "state2 = \"010010010011010100010101010110010111001111011001011010011011011100011101011110011111100000100001000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001000010000000000100000101000110000111001000001001001010001011001100011000001110000000010000\"\n",
    "state1 == state2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+\n",
      "|count(DISTINCT state_prior)|\n",
      "+---------------------------+\n",
      "|                  137945351|\n",
      "+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combined_policy_df.select(countDistinct('state_prior')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155223976"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_policy_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv /data_data/reinforcement_learning/results/combined_policy_file /data_data/reinforcement_learning/results/combined_policy_file.bak\n",
    "!touch /data_data/reinforcement_learning/results/combined_policy_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat /data_data/reinforcement_learning/results/*.json/part-*.json >> /data_data/reinforcement_learning/results/combined_policy_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sc.stop()\n",
    "    \n",
    "    spark.stop()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import ast\n",
    "\n",
    "combined_policy_dict = defaultdict()\n",
    "\n",
    "with open('/data_data/reinforcement_learning/results/combined_policy_file','r') as policy_file:\n",
    "    policies = policy_file.readlines()\n",
    "    for policy_ in policies:\n",
    "        policy = ast.literal_eval(policy_)\n",
    "        state_prior, expected_value, pol = policy.values()\n",
    "        if not state_prior in combined_policy_dict:\n",
    "            combined_policy_dict[state_prior] = {}\n",
    "            combined_policy_dict[state_prior][\"policy\"] = pol\n",
    "            combined_policy_dict[state_prior][\"value\"]  = expected_value\n",
    "        else:\n",
    "            curr_policy_value = combined_policy_dict[state_prior]['value']\n",
    "            if expected_value > curr_policy_value:\n",
    "                combined_policy_dict[state_prior][\"policy\"] = pol\n",
    "                combined_policy_dict[state_prior][\"value\"]  = expected_value\n",
    "            else:\n",
    "                pass\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined_policy_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('/data_data/reinforcement_learning/results/combined_file','w') as output_file:\n",
    "    for state, action in combined_policy_dict.items():\n",
    "        output_string = str(state) + \"\\t\" + str(action) +\"\\n\"\n",
    "        output_file.write(output_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.7.6"
=======
   "version": "3.8.2"
>>>>>>> 5b2a6ec6a166a9715ccea73f18615d07b2c58aa4
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
