{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "\n",
    "import platform\n",
    "platform.python_version()\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "#pd.set_option('display.height', 1000)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', 800)\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "pd.set_option('expand_frame_repr', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER = !whoami\n",
    "USER = USER[0]\n",
    "OUTPUT_PATH_BASE = '/user/{USER}'.format(USER=USER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export HADOOP_HOME=/usr/local/hadoop\n",
    "!export HADOOP_OPTS=\"-Dhadoop.tmp.dir=/user/ubuntu/tmp\"\n",
    "#!sudo ln -s /usr/lib/hadoop-mapreduce/hadoop-streaming.jar /usr/lib/hadoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!head -n 100 /data_data/History_file_1000000_trials_2_sides_Feb_28_2020_0719 >  /data_data/History_100.csv\n",
    "#!hdfs dfs -put /data_data/History_100.csv {OUTPUT_PATH_BASE}/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls -lh /data_data/reinforcement_learning/results/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv /data_data/reinforcement_learning/results/history_file_2000000_trials_2_sides_May_05_2020_0939 /data_data/reinforcement_learning/results/history_file_2M_test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!head -n 5 /data_data/reinforcement_learning/results/history_file_2M_test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting transitionMatrix.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile transitionMatrix.py\n",
    "\n",
    "from __future__ import division\n",
    "import mrjob\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "from collections import defaultdict, Counter\n",
    "import re\n",
    "import ast\n",
    "\n",
    "\n",
    "class MRtransitionMatrix(MRJob):\n",
    "    \n",
    "    def steps(self):\n",
    "        return [MRStep(\n",
    "                    mapper=self.mapper,\n",
    "                   reducer=self.reducer)]\n",
    "            \n",
    "    def mapper(self, _, lines_):\n",
    "        lines = lines_.split(\"\\n\")\n",
    "\n",
    "        for line_ in lines:\n",
    "            try:\n",
    "                cycle,trans = line_.replace(\"\\\"\",\"'\").split(\"\\t\")\n",
    "                transitions = ast.literal_eval(trans)\n",
    "                for item in transitions:\n",
    "                    move_count = int(item[0])\n",
    "                    if move_count % 2 == 0:\n",
    "                        yield int(cycle), item\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "                \n",
    "        \n",
    "        \n",
    "    def reducer(self, history, values):\n",
    "        episodes = []\n",
    "        \n",
    "        initial_state = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1]\n",
    "        \n",
    "        piece_value_dict = {\"0\":0, \"1\":5,\"2\":3,\"3\":3,\"4\":9,\"5\":20,\"6\":3,\"7\":3,\"8\":5,\"9\":1,\"10\":1,\"11\":1,\"12\":1,\"13\":1,\"14\":1,\"15\":1,\"16\":1,\"-16\":-1,\"-15\":-1,\"-14\":-1,\"-13\":-1,\"-12\":-1,\"-11\":-1,\"-10\":-1,\"-9\":-1,\"-8\":-5,\"-7\":-3,\"-6\":-3,\"-5\":-9,\"-4\":-20,\"-3\":-3,\"-2\":-3,\"-1\":-5}\n",
    "        \n",
    "        history_ = []\n",
    "        \n",
    "        for value in values:\n",
    "            #num_turns += 1\n",
    "            try:\n",
    "\n",
    "                episodes.append(value)   \n",
    "                \n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "        #yield history, episode          \n",
    "        \n",
    "        num_states = len(episodes) \n",
    "        \n",
    "        for num in range(num_states):\n",
    "            state = ast.literal_eval(episodes[num][1])\n",
    "            \n",
    "            try:\n",
    "                state_prime = ast.literal_eval(episodes[num+1][1])\n",
    "            except:\n",
    "                state_prime = ast.literal_eval(episodes[num][1])\n",
    "                \n",
    "            move        = ast.literal_eval(episodes[num][0])\n",
    "            value       = sum([int(piece_value_dict[str(x)]) for x in state])\n",
    "            value_prime = sum([int(piece_value_dict[str(x)]) for x in state_prime])\n",
    "            action      = episodes[num][3]\n",
    "            reward      = value_prime - value\n",
    "            Value       = 0\n",
    "            \n",
    "            history_.append([history,[move, state, action, state_prime, value, value_prime, reward, Value]])\n",
    "            \n",
    "                            \n",
    "        rewards = []\n",
    "                            \n",
    "        for histry in history_:\n",
    "            rewards.append(histry[1][6])\n",
    "        \n",
    "        num_values = len(rewards)\n",
    "\n",
    "        gamma = 0.5\n",
    "\n",
    "        counter = 0\n",
    "\n",
    "        Values = []\n",
    "\n",
    "        for reward in rewards[::-1]:\n",
    "            if counter == 0:\n",
    "                Values.append(round(reward,6))\n",
    "            else:\n",
    "                Values.append(round(reward + gamma*Values[counter-1],6))\n",
    "\n",
    "            counter += 1\n",
    "\n",
    "        Values = Values[::-1]\n",
    "\n",
    "        for val in range(num_values):\n",
    "            \n",
    "            #yield str(type(Values[val])), str(type(history_[val][1][7]))\n",
    "            history_[val][1][7] = Values[val]\n",
    "            \n",
    "        for hist in history_:\n",
    "            #yield history, ({\"state_action\": (hist[1][1],hist[1][2]),\"state_prime\": hist[1][3], \"value\": hist[1][7]})\n",
    "            #yield (hist[1][1], hist[1][2]), hist[1][3]\n",
    "            yield None, {history: {\"state\": hist[1][1],\"action\":hist[1][2],\"state_prime\": hist[1][3], \"reward\":reward, \"Value\": hist[1][7]}}\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    MRtransitionMatrix.run() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source:\r\n"
     ]
    }
   ],
   "source": [
    "!whereis source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#!hdfs dfs -ls /user/ubuntu/data/history_file_500K_test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/bin:/home/ubuntu/anaconda3/bin:/home/ubuntu/anaconda3/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/hadoop/hadoop-2.8.0/sbin:/home/hadoop/hadoop-2.8.0/bin\r\n"
     ]
    }
   ],
   "source": [
    "!echo $PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for local runner\n",
      "Creating temp directory /tmp/transitionMatrix.ubuntu.20200506.131254.254523\n",
      "Running step 1 of 1...\n",
      "job output is in /data_data/reinforcement_learning/results/sarsa\n",
      "Removing temp directory /tmp/transitionMatrix.ubuntu.20200506.131254.254523...\n"
     ]
    }
   ],
   "source": [
    "#!hdfs dfs -rm /user/ubuntu/data/history_file_500K_test.csv\n",
    "\n",
    "!rm -rf /data_data/reinforcement_learning/results/sarsa\n",
    "\n",
    "!rm -rf /data_data/reinforcement_learning/results/history_sarsa_2M_test\n",
    "\n",
    "!python /home/ubuntu/transitionMatrix.py /data_data/reinforcement_learning/results/history_file_2M_test.csv -r local --output-dir=/data_data/reinforcement_learning/results/sarsa \n",
    "\n",
    "#!hdfs dfs -put /data_data/reinforcement_learning/results/history_file_500K_test.csv /user/ubuntu/data/\n",
    "\n",
    "!cat /data_data/reinforcement_learning/results/sarsa/part-* >> /data_data/reinforcement_learning/results/history_sarsa_2M_test.tsv\n",
    "\n",
    "!rm -rf /data_data/reinforcement_learning/results/sarsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null\t{\"999999\":{\"state\":[1,2,3,4,0,5,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,0,7,8,9,0,0,0,0,0,10,11,0,0,0,0,0,0,0,0,0,12,0,0,13,14,0,0,0,15,16,-16,0,-15,0,-14],\"action\":\"[Rook,(1,0),(3,7),(4,7)]\",\"state_prime\":[1,2,3,4,0,5,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,0,7,0,8,0,0,0,0,0,9,10,0,0,11,0,0,0,0,0,0,0,0,0,12,13,0,0,0,14,15,16,0,-16,0,-15],\"reward\":0,\"Value\":1.125}}\r\n",
      "null\t{\"999999\":{\"state\":[1,2,3,4,0,5,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,0,7,0,8,0,0,0,0,0,9,10,0,0,11,0,0,0,0,0,0,0,0,0,12,13,0,0,0,14,15,16,0,-16,0,-15],\"action\":\"[Rook,(1,0),(4,7),(5,7)]\",\"state_prime\":[1,2,3,4,0,5,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,7,0,0,0,0,0,8,0,0,0,0,0,0,0,9,0,0,0,10,0,0,0,0,11,0,0,0,0,12,13,0,0,0,14,15,16,0,-16,0,-15],\"reward\":0,\"Value\":0.25}}\r\n",
      "null\t{\"999999\":{\"state\":[1,2,3,4,0,5,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,7,0,0,0,0,0,8,0,0,0,0,0,0,0,9,0,0,0,10,0,0,0,0,11,0,0,0,0,12,13,0,0,0,14,15,16,0,-16,0,-15],\"action\":\"[Bishop,(1,-1),(6,5),(7,4)]\",\"state_prime\":[1,2,3,4,0,5,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,7,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,9,0,0,0,10,0,0,0,0,11,0,0,0,0,12,0,0,0,0,13,14,15,16,-16,0,-15],\"reward\":0,\"Value\":0.5}}\r\n",
      "null\t{\"999999\":{\"state\":[1,2,3,4,0,5,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,7,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,9,0,0,0,10,0,0,0,0,11,0,0,0,0,12,0,0,0,0,13,14,15,16,-16,0,-15],\"action\":\"[Rook,(1,0),(2,0),(3,0)]\",\"state_prime\":[1,2,3,4,0,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,0,7,0,0,0,0,0,0,0,0,8,0,0,0,0,9,0,0,0,0,0,0,0,0,10,0,0,0,0,11,0,0,0,0,12,13,14,15,16,0,-16],\"reward\":0,\"Value\":1.0}}\r\n",
      "null\t{\"999999\":{\"state\":[1,2,3,4,0,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,0,7,0,0,0,0,0,0,0,0,8,0,0,0,0,9,0,0,0,0,0,0,0,0,10,0,0,0,0,11,0,0,0,0,12,13,14,15,16,0,-16],\"action\":\"[Rook,(1,0),(5,7),(6,7)]\",\"state_prime\":[1,2,3,4,0,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,0,7,0,0,0,0,0,0,0,0,8,0,0,0,0,9,0,0,0,0,0,0,0,0,10,0,0,0,0,11,0,0,0,0,12,13,14,15,16,0,-16],\"reward\":0,\"Value\":0}}\r\n"
     ]
    }
   ],
   "source": [
    "!tail -n 5 /data_data/reinforcement_learning/results/history_sarsa_2M_test.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Transition Matrix for Full Run.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Compute State_Action Transition Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting getUniqueStateProbability.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile getUniqueStateProbability.py\n",
    "#!~/usr/bin/python\n",
    "\n",
    "from __future__ import division\n",
    "import re\n",
    "import mrjob\n",
    "import json,ast\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "\n",
    "class getUniqueStateProbability(MRJob):\n",
    "    MRJob.SORT_VALUES = False\n",
    "\n",
    "    def mapper(self, _, line_):\n",
    "        try:\n",
    "            x,_line = line_.split(\"\\t\")\n",
    "            line    = ast.literal_eval(_line)\n",
    "            for cycle in line.keys():\n",
    "                state   = line[cycle]['state']\n",
    "                action  = line[cycle]['action']\n",
    "                state_prime = line[cycle]['state_prime']\n",
    "                reward  = line[cycle]['reward']\n",
    "                Value   = line[cycle]['Value']\n",
    "            \n",
    "            yield (state, action, state_prime, Value),1\n",
    "        except:\n",
    "            yield \"failed\", None\n",
    "            \n",
    "            \n",
    "    def reducer(self, state_action_prime, count):\n",
    "\n",
    "        frequency = sum(count)\n",
    "        state = state_action_prime[0]\n",
    "        state_action = state_action_prime[:2]\n",
    "        Value = state_action_prime[3]\n",
    "        state_prime  = state_action_prime[2]\n",
    "        prime_freq   = (state_prime, frequency)\n",
    "        #yield state_action, prime_freq\n",
    "        yield state, Value\n",
    "\n",
    "    def steps(self):  \n",
    "        jobconf2 = {'mapreduce.job.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "                    'stream.num.map.output.key.field':1, \n",
    "                    'mapreduce.partition.keycomparator.options': '-k1,k2nr'}  \n",
    "        return [MRStep(mapper=self.mapper,\n",
    "                      reducer=self.reducer)]\n",
    "    \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    getUniqueStateProbability.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE_FREQUENCY_OUT = \"/data_data/reinforcement_learning/results/STATE_FREQUENCY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm  /data_data/reinforcement_learning/results/state_value_sarsa_1k.tsv \n",
    "#!rm -rf /data_data/reinforcement_learning/results/STATE_FREQUENCY/\n",
    "#!python getUniqueStateProbability.py -r local /data_data/reinforcement_learning/results/history_sarsa_1k_test --output-dir={STATE_FREQUENCY_OUT} --no-output\n",
    "#!cat  /data_data/reinforcement_learning/results/STATE_FREQUENCY/part-* >>  /data_data/reinforcement_learning/results/state_value_sarsa_1k.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!tail -n 5  /data_data/reinforcement_learning/results/state_value_sarsa_1k.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/data_data/reinforcement_learning/results/state_value_sarsa_2M.tsv': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for local runner\n",
      "Creating temp directory /tmp/getUniqueStateProbability.ubuntu.20200506.162341.561459\n",
      "Running step 1 of 1...\n",
      "job output is in /data_data/reinforcement_learning/results/STATE_FREQUENCY\n",
      "Removing temp directory /tmp/getUniqueStateProbability.ubuntu.20200506.162341.561459...\n"
     ]
    }
   ],
   "source": [
    "!rm  /data_data/reinforcement_learning/results/state_value_sarsa_2M.tsv \n",
    "!rm -rf /data_data/reinforcement_learning/results/STATE_FREQUENCY/\n",
    "!python getUniqueStateProbability.py -r local /data_data/reinforcement_learning/results/history_sarsa_2M_test.tsv --output-dir={STATE_FREQUENCY_OUT} --no-output\n",
    "!cat  /data_data/reinforcement_learning/results/STATE_FREQUENCY/part-* >>  /data_data/reinforcement_learning/results/state_value_sarsa_2M.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1]\t1.000015\r\n",
      "[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1]\t1.001411\r\n",
      "[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1]\t1.250439\r\n",
      "[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1]\t1.252004\r\n",
      "[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1]\t1.352146\r\n"
     ]
    }
   ],
   "source": [
    "!tail -n 5  /data_data/reinforcement_learning/results/state_value_sarsa_2M.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Average Value for a State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting getAverageValueForStates.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile getAverageValueForStates.py\n",
    "#!~/usr/bin/python\n",
    "\n",
    "from __future__ import division\n",
    "import re\n",
    "import mrjob\n",
    "import json\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "from collections import defaultdict, Counter\n",
    "import ast\n",
    "\n",
    "class getAverageValueForStates(MRJob):\n",
    "    MRJob.SORT_VALUES = False\n",
    "\n",
    "    def mapper(self, _, line_):\n",
    "        try:\n",
    "            #state, values = line_\n",
    "            state, values = line_.replace(\"]\",\"]::::\").split(\"::::\")\n",
    "            yield ast.literal_eval(state), float(values[2:])\n",
    "        except:\n",
    "            yield None, None\n",
    "\n",
    "    def reducer(self, state, values):\n",
    "        temp_arr = [value for value in values]\n",
    "\n",
    "        try:\n",
    "            num_values = int(len(temp_arr))\n",
    "            sum_values = sum(temp_arr)\n",
    "            avg_value  = round(sum_values/num_values,6)\n",
    "            yield state, avg_value\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    def steps(self):  \n",
    "        jobconf2 = {'mapreduce.job.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "                    'stream.num.map.output.key.field':1, \n",
    "                    'mapreduce.partition.keycomparator.options': '-k1,k2nr'}  \n",
    "        return [MRStep(mapper=self.mapper,\n",
    "                      reducer=self.reducer)]\n",
    "    \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    getAverageValueForStates.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm  /data_data/reinforcement_learning/results/state_avg_value_sarsa_1k.tsv \n",
    "#!rm -rf /data_data/reinforcement_learning/results/STATE_FREQUENCY/\n",
    "#!python getAverageValueForStates.py -r local /data_data/reinforcement_learning/results/state_value_sarsa_1k.tsv --output-dir={STATE_FREQUENCY_OUT} --no-output\n",
    "#!cat  /data_data/reinforcement_learning/results/STATE_FREQUENCY/part-* >>  /data_data/reinforcement_learning/results/state_avg_value_sarsa_1k.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!head -n 10 /data_data/reinforcement_learning/results/state_avg_value_sarsa_1k.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/data_data/reinforcement_learning/results/state_avg_value_sarsa_2M.tsv': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for local runner\n",
      "Creating temp directory /tmp/getAverageValueForStates.ubuntu.20200506.195936.789930\n",
      "Running step 1 of 1...\n",
      "job output is in /data_data/reinforcement_learning/results/STATE_FREQUENCY\n",
      "Removing temp directory /tmp/getAverageValueForStates.ubuntu.20200506.195936.789930...\n"
     ]
    }
   ],
   "source": [
    "!rm  /data_data/reinforcement_learning/results/state_avg_value_sarsa_2M.tsv \n",
    "!rm -rf /data_data/reinforcement_learning/results/STATE_FREQUENCY/\n",
    "!python getAverageValueForStates.py -r local /data_data/reinforcement_learning/results/state_value_sarsa_2M.tsv --output-dir={STATE_FREQUENCY_OUT} --no-output\n",
    "!cat  /data_data/reinforcement_learning/results/STATE_FREQUENCY/part-* >>  /data_data/reinforcement_learning/results/state_avg_value_sarsa_2M.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,2,3,0,0,4,0,5,0,0,0,0,0,0,0,0,6,0,7,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0]\t0.012451\r\n",
      "[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,0,3,4,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,6,0,7,0,0,0,0,0,0,0,0,8,9,0,10,0,0,0,0]\t0.435902\r\n",
      "[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,0,3,4,5,0,6,0,0,0,0,0,0,0,7,0,0,0,0,8,0,0,0,0,0,0,9,0,0,0,0,0,0,0,0,0,0,0,0]\t1.398434\r\n",
      "[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,3,0,4,5,0,6,0,0,0,0,0,7,0,0,0,0,8,0,0,0,9,0,0,0,0,0,0,0,0,0,10,0,0,0,0,0,0,0]\t0.206993\r\n",
      "[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,3,0,4,5,0,6,0,0,0,0,7,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,9,0,10,0,0,0,0,11,0,0,0]\t0.003296\r\n",
      "[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,3,0,4,5,0,6,0,0,0,0,7,0,0,8,0,0,0,9,0,10,0,0,0,0,0,0,0,11,0,12,0,0,0,0,13,0,0,0]\t2.001648\r\n",
      "[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,3,0,4,5,0,6,0,0,0,7,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,10,0,0,0,0,0,0,0]\t0.413986\r\n",
      "[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,2,3,0,0,0,4,5,6,0,0,0,7,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0,0,9,0,0,0,0]\t0.503112\r\n",
      "[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,2,0,3,4,0,0,0,0,5,0,0,0,0,6,0,0,0,7,0,8,0,0,0,0,0,0,0,0,0,0,9,0,0,0,0]\t1.006225\r\n",
      "[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,2,3,0,4,0,0,5,6,0,0,7,0,0,0,0,0,0,0,0,8,0,0,0,0,0,9,10,0,0,0,0,11,0,0,0,0,0,0,0]\t0.605388\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 10 /data_data/reinforcement_learning/results/state_avg_value_sarsa_2M.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114697411\r\n"
     ]
    }
   ],
   "source": [
    "!cat /data_data/reinforcement_learning/results/state_avg_value_sarsa_2M.tsv | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POLICY SEARCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Transition Frequencies and Probabilities. Derive Transition matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting getUniqueStateProbability.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile getUniqueStateProbability.py\n",
    "#!~/usr/bin/python\n",
    "\n",
    "from __future__ import division\n",
    "import re\n",
    "import mrjob\n",
    "import json,ast\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "\n",
    "class getUniqueStateProbability(MRJob):\n",
    "    MRJob.SORT_VALUES = False\n",
    "\n",
    "    def mapper(self, _, line_):\n",
    "        try:\n",
    "            x,_line = line_.split(\"\\t\")\n",
    "            line    = ast.literal_eval(_line)\n",
    "            for cycle in line.keys():\n",
    "                state   = line[cycle]['state']\n",
    "                action  = line[cycle]['action']\n",
    "                state_prime = line[cycle]['state_prime']\n",
    "                reward  = line[cycle]['reward']\n",
    "                Value   = line[cycle]['Value']\n",
    "            \n",
    "            yield (state, action, state_prime),1\n",
    "        except:\n",
    "            yield \"failed\", None\n",
    "            \n",
    "            \n",
    "    def reducer(self, state_action_prime, count):\n",
    "\n",
    "        frequency = sum(count)\n",
    "        #state = state_action_prime[0]\n",
    "        #state_action = state_action_prime[:2]\n",
    "        #Value = state_action_prime[3]\n",
    "        #state_prime  = state_action_prime[2]\n",
    "        #prime_freq   = (state_prime, frequency)\n",
    "        yield state_action_prime, frequency\n",
    "\n",
    "    def steps(self):  \n",
    "        jobconf2 = {'mapreduce.job.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "                    'stream.num.map.output.key.field':1, \n",
    "                    'mapreduce.partition.keycomparator.options': '-k1,k2nr'}  \n",
    "        return [MRStep(mapper=self.mapper,\n",
    "                      reducer=self.reducer)]\n",
    "    \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    getUniqueStateProbability.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm  /data_data/reinforcement_learning/results/state_transition_sarsa_1k.tsv \n",
    "#!rm -rf /data_data/reinforcement_learning/results/STATE_FREQUENCY/\n",
    "#!python getUniqueStateProbability.py -r local /data_data/reinforcement_learning/results/history_sarsa_1k_test --output-dir={STATE_FREQUENCY_OUT} --no-output\n",
    "#!cat  /data_data/reinforcement_learning/results/STATE_FREQUENCY/part-* >>  /data_data/reinforcement_learning/results/state_transition_sarsa_1k.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!head -n 5  /data_data/reinforcement_learning/results/state_transition_sarsa_1k.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/data_data/reinforcement_learning/results/state_transition_sarsa_2M.tsv': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for local runner\n",
      "Creating temp directory /tmp/getUniqueStateProbability.ubuntu.20200506.203955.283922\n",
      "Running step 1 of 1...\n",
      "job output is in /data_data/reinforcement_learning/results/STATE_FREQUENCY\n",
      "Removing temp directory /tmp/getUniqueStateProbability.ubuntu.20200506.203955.283922...\n"
     ]
    }
   ],
   "source": [
    "!rm  /data_data/reinforcement_learning/results/state_transition_sarsa_2M.tsv \n",
    "!rm -rf /data_data/reinforcement_learning/results/STATE_FREQUENCY/\n",
    "!python getUniqueStateProbability.py -r local /data_data/reinforcement_learning/results/history_sarsa_2M_test.tsv --output-dir={STATE_FREQUENCY_OUT} --no-output\n",
    "!cat  /data_data/reinforcement_learning/results/STATE_FREQUENCY/part-* >>  /data_data/reinforcement_learning/results/state_transition_sarsa_2M.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1],\"[Pawn,(1,1),(1,6),(2,7)]\",[1,2,3,4,5,6,7,8,9,10,11,12,13,14,0,15,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,0,-15,-14,-13,-12,-11,-10,0,-9,-8,-7,-6,-5,-4,-3,-2,-1]]\t4770\r\n",
      "[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1],\"[Pawn,(1,1),(1,6),(2,7)]\",[1,2,3,4,5,6,7,8,9,10,11,12,13,14,0,15,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,0,-15,-14,-13,-12,-11,0,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1]]\t4660\r\n",
      "[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1],\"[Pawn,(1,1),(1,6),(2,7)]\",[1,2,3,4,5,6,7,8,9,10,11,12,13,14,0,15,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,0,-1]]\t7718\r\n",
      "[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1],\"[Pawn,(1,1),(1,6),(2,7)]\",[1,2,3,4,5,6,7,8,9,10,11,12,13,14,0,15,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,-9,0,-8,-7,-6,-5,-4,-3,-2,-1]]\t4970\r\n",
      "[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1],\"[Pawn,(1,1),(1,6),(2,7)]\",[1,2,3,4,5,6,7,8,9,10,11,12,13,14,0,15,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,0,-9,-8,-7,-6,-5,-4,-3,-2,-1]]\t4824\r\n"
     ]
    }
   ],
   "source": [
    "!tail -n 5  /data_data/reinforcement_learning/results/state_transition_sarsa_2M.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a compact representation of game states using one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,2,3,0,0,4,0,5,0,0,0,0,0,0,0,0,6,0,7,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0]\t0.012451\r\n",
      "[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,0,3,4,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,6,0,7,0,0,0,0,0,0,0,0,8,9,0,10,0,0,0,0]\t0.435902\r\n",
      "[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,0,3,4,5,0,6,0,0,0,0,0,0,0,7,0,0,0,0,8,0,0,0,0,0,0,9,0,0,0,0,0,0,0,0,0,0,0,0]\t1.398434\r\n",
      "[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,3,0,4,5,0,6,0,0,0,0,0,7,0,0,0,0,8,0,0,0,9,0,0,0,0,0,0,0,0,0,10,0,0,0,0,0,0,0]\t0.206993\r\n",
      "[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,3,0,4,5,0,6,0,0,0,0,7,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,9,0,10,0,0,0,0,11,0,0,0]\t0.003296\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 /data_data/reinforcement_learning/results/state_avg_value_sarsa_2M.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/data_data/reinforcement_learning/results/unique_states_2M.tsv': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!rm /data_data/reinforcement_learning/results/unique_states_2M.tsv\n",
    "!cat /data_data/reinforcement_learning/results/state_avg_value_sarsa_2M.tsv | awk -F\"\\t\" '{print $1}' >> /data_data/reinforcement_learning/results/unique_states_2M.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Version I: Get unique states "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import ast\n",
    "#from collections import defaultdict\n",
    "\n",
    "#unique_states_file = \"/data_data/reinforcement_learning/results/unique_states_500K.tsv\"\n",
    "\n",
    "#unique_states_dict = defaultdict()\n",
    "\n",
    "#state_index = 0\n",
    "\n",
    "#with open(unique_states_file,'r') as all_unique_states:\n",
    "    \n",
    "#    unique_states = all_unique_states.readlines()\n",
    "    \n",
    "#    for unique_state in unique_states:\n",
    "        \n",
    "#        unique_states_dict[unique_state.strip()] = state_index\n",
    "        \n",
    "#        state_index += 1\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(unique_states_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Version II: Get unique states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1],\"[Pawn,(1,1),(1,6),(2,7)]\",[1,2,3,4,5,6,7,8,9,10,11,12,13,14,0,15,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,0,-15,-14,-13,-12,-11,-10,0,-9,-8,-7,-6,-5,-4,-3,-2,-1]]\t4770\r\n",
      "[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1],\"[Pawn,(1,1),(1,6),(2,7)]\",[1,2,3,4,5,6,7,8,9,10,11,12,13,14,0,15,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,0,-15,-14,-13,-12,-11,0,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1]]\t4660\r\n",
      "[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1],\"[Pawn,(1,1),(1,6),(2,7)]\",[1,2,3,4,5,6,7,8,9,10,11,12,13,14,0,15,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,0,-1]]\t7718\r\n",
      "[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1],\"[Pawn,(1,1),(1,6),(2,7)]\",[1,2,3,4,5,6,7,8,9,10,11,12,13,14,0,15,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,-9,0,-8,-7,-6,-5,-4,-3,-2,-1]]\t4970\r\n",
      "[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1],\"[Pawn,(1,1),(1,6),(2,7)]\",[1,2,3,4,5,6,7,8,9,10,11,12,13,14,0,15,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,0,-9,-8,-7,-6,-5,-4,-3,-2,-1]]\t4824\r\n"
     ]
    }
   ],
   "source": [
    "!tail -n 5  /data_data/reinforcement_learning/results/state_transition_sarsa_2M.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting getUniqueStateOrderedByCounts.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile getUniqueStateOrderedByCounts.py\n",
    "#!~/usr/bin/python\n",
    "\n",
    "from __future__ import division\n",
    "import re\n",
    "import mrjob\n",
    "import json,ast\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "\n",
    "class getUniqueStateOrderedByCounts(MRJob):\n",
    "    MRJob.SORT_VALUES = False\n",
    "\n",
    "    def mapper(self, _, line_):\n",
    "        try:\n",
    "            x,_line = line_.split(\"\\t\")\n",
    "            line    = ast.literal_eval(_line)\n",
    "            for cycle in line.keys():\n",
    "                state   = line[cycle]['state']\n",
    "                action  = line[cycle]['action']\n",
    "                state_prime = line[cycle]['state_prime']\n",
    "                reward  = line[cycle]['reward']\n",
    "                Value   = line[cycle]['Value']\n",
    "            \n",
    "            yield state,1\n",
    "            yield state_prime, 1\n",
    "        except:\n",
    "            yield \"failed\", None\n",
    "            \n",
    "            \n",
    "    def reducer(self, state, count):\n",
    "        frequency = sum(count)\n",
    "        yield state, frequency\n",
    "\n",
    "    def steps(self):  \n",
    "        jobconf2 = {'mapreduce.job.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "                    'stream.num.map.output.key.field':1, \n",
    "                    'mapreduce.partition.keycomparator.options': '-k1,k2n'}  \n",
    "        return [MRStep(mapper=self.mapper,\n",
    "                      reducer=self.reducer)]\n",
    "    \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    getUniqueStateOrderedByCounts.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for local runner\n",
      "Creating temp directory /tmp/getUniqueStateOrderedByCounts.ubuntu.20200507.000838.778440\n",
      "Running step 1 of 1...\n",
      "job output is in /data_data/reinforcement_learning/results/STATE_COUNTS/\n",
      "Removing temp directory /tmp/getUniqueStateOrderedByCounts.ubuntu.20200507.000838.778440...\n"
     ]
    }
   ],
   "source": [
    "!rm  /data_data/reinforcement_learning/results/unique_states_ordered_by_counts_1K.tsv\n",
    "!rm  /data_data/reinforcement_learning/results/unique_states_ordered_by_counts_1K_.tsv\n",
    "!rm /data_data/reinforcement_learning/results/unique_states_ordered_by_counts_1K__.tsv\n",
    "\n",
    "!rm -rf /data_data/reinforcement_learning/results/STATE_COUNTS/\n",
    "\n",
    "!python getUniqueStateOrderedByCounts.py -r local /data_data/reinforcement_learning/results/history_sarsa_1k_test --output-dir=/data_data/reinforcement_learning/results/STATE_COUNTS/ --no-output\n",
    "\n",
    "!cat  /data_data/reinforcement_learning/results/STATE_COUNTS/part-* >>  /data_data/reinforcement_learning/results/unique_states_ordered_by_counts_1K__.tsv\n",
    "\n",
    "!tac /data_data/reinforcement_learning/results/unique_states_ordered_by_counts_1K__.tsv >> /data_data/reinforcement_learning/results/unique_states_ordered_by_counts_1K_.tsv\n",
    "\n",
    "!nawk '$1=(FNR FS $1)' /data_data/reinforcement_learning/results/unique_states_ordered_by_counts_1K_.tsv >> /data_data/reinforcement_learning/results/unique_states_ordered_by_counts_1K.tsv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499\r\n"
     ]
    }
   ],
   "source": [
    "!cat /data_data/reinforcement_learning/results/unique_states_ordered_by_counts_1K.tsv | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1] 25\r\n",
      "2 [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,0,0,-15,-14,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,0,-1] 4\r\n",
      "3 [1,2,3,4,5,6,7,8,9,10,11,12,13,14,0,15,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,0,0,0,0,0,0,-15,0,-14,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1] 4\r\n",
      "4 [1,2,3,4,5,6,7,8,9,10,11,0,12,13,14,15,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,0,-1] 4\r\n",
      "5 [1,2,3,4,5,6,7,8,9,10,11,0,12,13,14,15,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,0,0,0,-15,-14,-13,-12,-11,0,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1] 4\r\n",
      "6 [1,2,3,4,5,6,7,8,9,10,11,0,12,13,14,0,0,0,15,0,0,0,16,0,0,0,0,0,-16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-15,-14,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,0,-1] 4\r\n",
      "7 [1,2,3,4,5,6,7,8,9,10,0,11,12,13,14,15,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,0,0,0,0,0,-15,0,-14,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1] 4\r\n",
      "8 [1,2,3,4,5,6,7,8,9,10,0,11,12,13,14,15,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,0,0,0,0,0,-15,-14,-13,-12,-11,-10,-9,-8,-7,0,-6,-5,-4,-3,-2,-1] 4\r\n",
      "9 [1,2,3,4,5,6,7,8,9,10,0,11,12,13,14,0,0,0,0,15,0,0,16,0,0,-16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-15,-14,-13,-12,-11,-10,-9,-8,-7,0,-6,-5,-4,-3,-2,-1] 4\r\n",
      "10 [1,2,3,4,5,6,7,8,9,10,0,11,0,12,13,14,0,0,15,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,0,0,-15,0,0,-14,0,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,0,-1] 4\r\n"
     ]
    }
   ],
   "source": [
    "!head  /data_data/reinforcement_learning/results/unique_states_ordered_by_counts_1K.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/data_data/reinforcement_learning/results/unique_states_ordered_by_counts_2M.tsv': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for local runner\n",
      "Creating temp directory /tmp/getUniqueStateOrderedByCounts.ubuntu.20200507.000858.671330\n",
      "Running step 1 of 1...\n",
      "job output is in /data_data/reinforcement_learning/results/STATE_COUNTS/\n",
      "Removing temp directory /tmp/getUniqueStateOrderedByCounts.ubuntu.20200507.000858.671330...\n"
     ]
    }
   ],
   "source": [
    "!rm /data_data/reinforcement_learning/results/unique_states_ordered_by_counts_2M.tsv\n",
    "\n",
    "!rm -rf /data_data/reinforcement_learning/results/STATE_COUNTS/\n",
    "\n",
    "!python getUniqueStateOrderedByCounts.py -r local /data_data/reinforcement_learning/results/history_sarsa_2M_test.tsv --output-dir=/data_data/reinforcement_learning/results/STATE_COUNTS/ --no-output\n",
    "\n",
    "!cat  /data_data/reinforcement_learning/results/STATE_COUNTS/part-* >>  /data_data/reinforcement_learning/results/unique_states_ordered_by_counts_2M__.tsv\n",
    "\n",
    "!tac  /data_data/reinforcement_learning/results/unique_states_ordered_by_counts_2M__.tsv >> /data_data/reinforcement_learning/results/unique_states_ordered_by_counts_2M_.tsv\n",
    "!rm /data_data/reinforcement_learning/results/unique_states_ordered_by_counts_2M__.tsv\n",
    "\n",
    "!nawk '$1=(FNR FS $1)' /data_data/reinforcement_learning/results/unique_states_ordered_by_counts_2M_.tsv >> /data_data/reinforcement_learning/results/unique_states_ordered_by_counts_2M.tsv \n",
    "!rm /data_data/reinforcement_learning/results/unique_states_ordered_by_counts_2M_.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1] 6000000\r\n",
      "2 [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,0,0,0,0,-15,0,0,-14,0,-13,-12,-11,-10,-9,-8,-7,0,-6,-5,-4,-3,-2,-1] 4\r\n",
      "3 [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,0,0,0,0,0,0,0,0,0,-15,-14,-13,-12,-11,-10,-9,-8,-7,0,-6,-5,-4,-3,-2,-1] 8\r\n",
      "4 [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-15,-14,-13,-12,-11,-10,-9,-8,-7,0,-6,-5,-4,-3,-2,-1] 4\r\n",
      "5 [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,-16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-15,-14,-13,-12,-11,-10,-9,-8,-7,0,-6,-5,-4,-3,-2,-1] 4\r\n",
      "6 [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,0,0,0,0,0,0,0,0,0,0,0,-15,-14,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,0,-1] 4\r\n",
      "7 [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,0,0,0,0,0,0,0,0,0,-15,-14,-13,-12,-11,-10,-9,-8,-7,0,-6,-5,-4,-3,-2,-1] 4\r\n",
      "8 [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,0,0,0,0,0,0,0,0,0,0,-15,-14,-13,-12,-11,-10,-9,-8,-7,0,-6,-5,-4,-3,-2,-1] 4\r\n",
      "9 [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,-16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-15,-14,-13,-12,-11,-10,-9,-8,-7,0,-6,-5,-4,-3,-2,-1] 4\r\n",
      "10 [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,0,-2] 4\r\n"
     ]
    }
   ],
   "source": [
    "!head /data_data/reinforcement_learning/results/unique_states_ordered_by_counts_2M.tsv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 2000 /data_data/reinforcement_learning/results/unique_states_ordered_by_counts_2M.tsv  >> /data_data/reinforcement_learning/results/unique_states_ordered_by_counts_2K.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114697411\r\n"
     ]
    }
   ],
   "source": [
    "!cat /data_data/reinforcement_learning/results/unique_states_ordered_by_counts_2M.tsv | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting createUniqueStatesDict.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile createUniqueStatesDict.py\n",
    "#!~/usr/bin/python\n",
    "\n",
    "from __future__ import division\n",
    "import re\n",
    "import mrjob\n",
    "import json,ast\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "\n",
    "class createUniqueStatesDict(MRJob):\n",
    "    MRJob.SORT_VALUES = False\n",
    "\n",
    "    def mapper(self, _, line_):\n",
    "        try:\n",
    "            unique_id = int(line_.split(\" [\")[0])\n",
    "            state = str(\"[\" + line_.split(\" [\")[1].split(\"] \")[0] + \"]\")\n",
    "            yield state, unique_id\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "            \n",
    "    def reducer(self, unique_state, unique_ids):\n",
    "        \n",
    "        unique_states_dict = defaultdict()\n",
    "        \n",
    "        for unique_id in unique_ids:\n",
    "            yield \"{'\"+str(unique_state)+ \"':\" + str(unique_id)+\"}\", \"\\t\"\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    def steps(self):  \n",
    "        jobconf2 = {'mapreduce.job.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "                    'stream.num.map.output.key.field':1, \n",
    "                    'mapreduce.partition.keycomparator.options': '-k1,k2n'}  \n",
    "        return [MRStep(mapper=self.mapper,\n",
    "                      reducer=self.reducer)]\n",
    "    \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    createUniqueStatesDict.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for local runner\n",
      "Creating temp directory /tmp/createUniqueStatesDict.ubuntu.20200507.030356.532042\n",
      "Running step 1 of 1...\n",
      "job output is in /data_data/reinforcement_learning/results/UNIQUE_STATES/\n",
      "Removing temp directory /tmp/createUniqueStatesDict.ubuntu.20200507.030356.532042...\n"
     ]
    }
   ],
   "source": [
    "!rm /data_data/reinforcement_learning/results/unique_states_2K.tsv\n",
    "\n",
    "!rm -rf /data_data/reinforcement_learning/results/UNIQUE_STATES/\n",
    "\n",
    "!python createUniqueStatesDict.py -r local /data_data/reinforcement_learning/results/unique_states_ordered_by_counts_2K.tsv --output-dir=/data_data/reinforcement_learning/results/UNIQUE_STATES/ --no-output\n",
    "\n",
    "!sed 's/\"//g'  /data_data/reinforcement_learning/results/UNIQUE_STATES/part-* | awk -F \"\\t\" '{print $1}'  >>  /data_data/reinforcement_learning/results/unique_states_2K.tsv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 0, 15, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 0, 0, 0, -16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1]':2000}\r\n",
      "{'[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 0, 15, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 0, 0, 0, -16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1]':2000}\r\n",
      "{'[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 0, 15, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 0, 0, 0, 0, -16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -15, -14, -13, -12, -11, -10, -9, -8, -7, 0, -6, -5, -4, -3, -2, -1]':1999}\r\n",
      "{'[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 0, 15, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 0, 0, 0, 0, -16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -15, -14, -13, -12, -11, -10, -9, -8, -7, 0, -6, -5, -4, -3, -2, -1]':1999}\r\n",
      "{'[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 0, 15, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 0, 0, 0, 0, -16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -15, -14, -13, -12, 0, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1]':1998}\r\n",
      "{'[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 0, 15, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 0, 0, 0, 0, -16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -15, -14, -13, -12, 0, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1]':1998}\r\n",
      "{'[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 0, 15, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 0, 0, 0, 0, -16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -15, -14, -13, 0, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1]':1997}\r\n",
      "{'[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 0, 15, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 0, 0, 0, 0, -16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -15, -14, -13, 0, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1]':1997}\r\n",
      "{'[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 0, 15, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 0, 0, 0, 0, -16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -15, -14, 0, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1]':1996}\r\n",
      "{'[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 0, 15, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 0, 0, 0, 0, -16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -15, -14, 0, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1]':1996}\r\n"
     ]
    }
   ],
   "source": [
    "!head /data_data/reinforcement_learning/results/unique_states_2K.tsv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for local runner\n",
      "Creating temp directory /tmp/createUniqueStatesDict.ubuntu.20200507.030406.209119\n",
      "Running step 1 of 1...\n",
      "job output is in /data_data/reinforcement_learning/results/UNIQUE_STATES/\n",
      "Removing temp directory /tmp/createUniqueStatesDict.ubuntu.20200507.030406.209119...\n"
     ]
    }
   ],
   "source": [
    "!rm /data_data/reinforcement_learning/results/unique_states_2M.tsv\n",
    "\n",
    "!rm -rf /data_data/reinforcement_learning/results/UNIQUE_STATES/\n",
    "\n",
    "!python createUniqueStatesDict.py -r local /data_data/reinforcement_learning/results/unique_states_ordered_by_counts_2M.tsv --output-dir=/data_data/reinforcement_learning/results/UNIQUE_STATES/ --no-output\n",
    "\n",
    "!sed 's/\"//g'  /data_data/reinforcement_learning/results/UNIQUE_STATES/part-* | awk -F \"\\t\" '{print $1}'  >>  /data_data/reinforcement_learning/results/unique_states_2M.tsv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from collections import defaultdict\n",
    "\n",
    "unique_states_file = \"/data_data/reinforcement_learning/results/unique_states_2M.tsv\"\n",
    "\n",
    "unique_states_dict = defaultdict()\n",
    "\n",
    "state_index = 0\n",
    "\n",
    "with open(unique_states_file,'r') as all_unique_states:\n",
    "    \n",
    "    transitions = all_unique_states.readlines()\n",
    "    \n",
    "    for transition in transitions:\n",
    "        \n",
    "        unique_states_dict.update(ast.literal_eval(transition))\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114697411"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_states_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114697411"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_states_dict.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,2,3,0,0,4,0,5,0,0,0,0,0,0,0,0,6,0,7,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0]',\n",
       " '[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,0,3,4,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,6,0,7,0,0,0,0,0,0,0,0,8,9,0,10,0,0,0,0]',\n",
       " '[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,0,3,4,5,0,6,0,0,0,0,0,0,0,7,0,0,0,0,8,0,0,0,0,0,0,9,0,0,0,0,0,0,0,0,0,0,0,0]',\n",
       " '[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,3,0,4,5,0,6,0,0,0,0,0,7,0,0,0,0,8,0,0,0,9,0,0,0,0,0,0,0,0,0,10,0,0,0,0,0,0,0]',\n",
       " '[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,3,0,4,5,0,6,0,0,0,0,7,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,9,0,10,0,0,0,0,11,0,0,0]']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(unique_states_dict.keys())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### One hot encode Transition Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1],\"[Pawn,(1,1),(1,6),(2,7)]\",[1,2,3,4,5,6,7,8,9,10,11,12,13,14,0,15,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,0,-15,-14,-13,-12,-11,-10,0,-9,-8,-7,-6,-5,-4,-3,-2,-1]]\t4770\r\n",
      "[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1],\"[Pawn,(1,1),(1,6),(2,7)]\",[1,2,3,4,5,6,7,8,9,10,11,12,13,14,0,15,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,0,-15,-14,-13,-12,-11,0,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1]]\t4660\r\n",
      "[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1],\"[Pawn,(1,1),(1,6),(2,7)]\",[1,2,3,4,5,6,7,8,9,10,11,12,13,14,0,15,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,0,-1]]\t7718\r\n",
      "[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1],\"[Pawn,(1,1),(1,6),(2,7)]\",[1,2,3,4,5,6,7,8,9,10,11,12,13,14,0,15,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,-9,0,-8,-7,-6,-5,-4,-3,-2,-1]]\t4970\r\n",
      "[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1],\"[Pawn,(1,1),(1,6),(2,7)]\",[1,2,3,4,5,6,7,8,9,10,11,12,13,14,0,15,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,0,-9,-8,-7,-6,-5,-4,-3,-2,-1]]\t4824\r\n"
     ]
    }
   ],
   "source": [
    "!tail -n 5  /data_data/reinforcement_learning/results/state_transition_sarsa_2M.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### revisit this code block -- to extract total number of transitions earlier...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: /data_data/reinforcement_learning/results/state_transition_one_hot_2M.tsv: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!cat /data_data/reinforcement_learning/results/state_transition_one_hot_2M.tsv | awk -F\"\\t\" '{print $2}' >> /data_data/reinforcement_learning/results/state_transition_one_hot_sum_frequencies_2M.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to calculate this prior\n",
    "total_transitions = 12100292"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 ubuntu ubuntu 0 May  6 21:52 /data_data/reinforcement_learning/results/state_transition_one_hot_sum_frequencies_2M.tsv\r\n"
     ]
    }
   ],
   "source": [
    "!ls -alrth \"/data_data/reinforcement_learning/results/state_transition_one_hot_sum_frequencies_2M.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_transitions:\t0\n"
     ]
    }
   ],
   "source": [
    "transition_frequencies_file = \"/data_data/reinforcement_learning/results/state_transition_one_hot_sum_frequencies_2M.tsv\"\n",
    "\n",
    "total_transitions = 0\n",
    "\n",
    "with open(transition_frequencies_file,'r') as trans_freq_file:\n",
    "    transition_frequencies = trans_freq_file.readlines()\n",
    "    for transition_frequency in transition_frequencies:\n",
    "        total_transitions += round(float(transition_frequency.strip()))\n",
    "\n",
    "print(\"total_transitions:\\t{}\".format(total_transitions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_transitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate transition frequencies and use one-hot encoding to record states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First calculate frequency of (s,a) pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,2,3,0,0,4,0,5,0,0,0,0,0,0,0,0,6,0,7,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0],\"[Bishop,(1,1),(4,0),(5,1)]\",[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,2,0,0,0,3,0,4,0,0,0,5,0,0,0,0,6,0,7,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0]]\t2\r\n",
      "[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,0,3,4,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,6,0,7,0,0,0,0,0,0,0,0,8,9,0,10,0,0,0,0],\"[Rook,(1,0),(3,0),(4,0)]\",[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,2,0,3,0,0,0,0,4,0,0,0,0,0,0,5,0,0,0,0,0,6,0,7,0,0,0,0,0,0,0,0,8,9,0,10,0,0,0,0]]\t2\r\n",
      "[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,0,3,4,5,0,6,0,0,0,0,0,0,0,7,0,0,0,0,8,0,0,0,0,0,0,9,0,0,0,0,0,0,0,0,0,0,0,0],\"[Rook,(1,0),(3,7),(4,7)]\",[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,2,0,3,4,5,0,0,0,0,0,0,0,0,0,6,0,0,0,0,7,0,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0]]\t2\r\n",
      "[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,3,0,4,5,0,6,0,0,0,0,0,7,0,0,0,0,8,0,0,0,9,0,0,0,0,0,0,0,0,0,10,0,0,0,0,0,0,0],\"[Queen,(1,1),(5,6),(6,7)]\",[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,3,0,4,5,0,6,0,0,0,7,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,10,0,0,0,0,0,0,0]]\t2\r\n",
      "[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,3,0,4,5,0,6,0,0,0,0,7,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,9,0,10,0,0,0,0,11,0,0,0],\"[King,(1,-1),(3,2),(4,1)]\",[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,2,0,0,3,4,0,5,0,6,0,0,7,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,9,0,10,0,0,0,0,11,0,0,0]]\t2\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 /data_data/reinforcement_learning/results/state_transition_sarsa_2M.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting getStateActionFrequencies.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile getStateActionFrequencies.py\n",
    "#!~/usr/bin/python\n",
    "\n",
    "from __future__ import division\n",
    "import re\n",
    "import mrjob\n",
    "import json,ast\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "\n",
    "class getStateActionFrequencies(MRJob):\n",
    "    MRJob.SORT_VALUES = False\n",
    "\n",
    "    def mapper(self, _, state_action_prime_frequency):\n",
    "        try:\n",
    "            state_action = ast.literal_eval((state_action_prime_frequency.split(\"\\t\")[0]))[:2]\n",
    "            \n",
    "            yield state_action,int(1)\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "            \n",
    "    def reducer(self, state_action, counts):\n",
    "        \n",
    "        yield state_action, sum(counts)\n",
    "\n",
    "    def steps(self):  \n",
    "        jobconf2 = {'mapreduce.job.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "                    'stream.num.map.output.key.field':1, \n",
    "                    'mapreduce.partition.keycomparator.options': '-k1,k2nr'}  \n",
    "        return [MRStep(mapper=self.mapper,\n",
    "                      reducer=self.reducer)]\n",
    "    \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    getStateActionFrequencies.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "state_action_transitions_dict = defaultdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/data_data/reinforcement_learning/results/state_action_frequencies_2M.tsv': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for local runner\n",
      "Creating temp directory /tmp/getStateActionFrequencies.ubuntu.20200507.035257.158396\n",
      "Running step 1 of 1...\n",
      "job output is in /data_data/reinforcement_learning/results/STATE_FREQUENCY/\n",
      "Removing temp directory /tmp/getStateActionFrequencies.ubuntu.20200507.035257.158396...\n"
     ]
    }
   ],
   "source": [
    "state_transitions_file_verbose = \"/data_data/reinforcement_learning/results/state_transition_sarsa_2M.tsv\"\n",
    "\n",
    "state_action_transitions_dict = defaultdict()\n",
    "\n",
    "!rm -rf /data_data/reinforcement_learning/results/STATE_FREQUENCY/\n",
    "\n",
    "!rm /data_data/reinforcement_learning/results/state_action_frequencies_2M.tsv\n",
    "\n",
    "!python getStateActionFrequencies.py -r local /data_data/reinforcement_learning/results/state_transition_sarsa_2M.tsv --output-dir=/data_data/reinforcement_learning/results/STATE_FREQUENCY/ \n",
    "\n",
    "!cat /data_data/reinforcement_learning/results/STATE_FREQUENCY/part-* >> /data_data/reinforcement_learning/results/state_action_frequencies_2M.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1],\"[Pawn,(1,0),(1,5),(2,5)]\"]\t26\r\n",
      "[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1],\"[Pawn,(1,0),(1,6),(2,6)]\"]\t26\r\n",
      "[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1],\"[Pawn,(1,0),(1,7),(2,7)]\"]\t26\r\n",
      "[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1],\"[Pawn,(1,1),(1,0),(2,1)]\"]\t26\r\n",
      "[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1],\"[Pawn,(1,1),(1,1),(2,2)]\"]\t26\r\n",
      "[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1],\"[Pawn,(1,1),(1,2),(2,3)]\"]\t26\r\n",
      "[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1],\"[Pawn,(1,1),(1,3),(2,4)]\"]\t26\r\n",
      "[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1],\"[Pawn,(1,1),(1,4),(2,5)]\"]\t26\r\n",
      "[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1],\"[Pawn,(1,1),(1,5),(2,6)]\"]\t26\r\n",
      "[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1],\"[Pawn,(1,1),(1,6),(2,7)]\"]\t26\r\n"
     ]
    }
   ],
   "source": [
    "!tail -n 10 /data_data/reinforcement_learning/results/state_action_frequencies_2M.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import ast\n",
    "\n",
    "sa_transition_probs = defaultdict()\n",
    "\n",
    "sa_freqs = \"/data_data/reinforcement_learning/results/state_action_frequencies_2M.tsv\"\n",
    "\n",
    "with open(sa_freqs,'r') as sa_freqs_file:\n",
    "    sa_frequencies = sa_freqs_file.readlines()\n",
    "    for sa_frequency_ in sa_frequencies:\n",
    "        #state, action, frequency = ast.literal_eval(sa_frequency_.strip().replace(\"\\\"\",\"'\").split(\"\\t\"))\n",
    "        state_action, frequency = sa_frequency_.strip().replace(\"\\\"\",\"'\").split(\"\\t\")\n",
    "\n",
    "        sa_transition_probs[state_action] = int(frequency)\n",
    "\n",
    "#sa_transition_probs.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116271973"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sa_transition_probs.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,2,3,0,0,4,0,5,0,0,0,0,0,0,0,0,6,0,7,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0],\"[Bishop,(1,1),(4,0),(5,1)]\",[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,2,0,0,0,3,0,4,0,0,0,5,0,0,0,0,6,0,7,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0]]\t2\r\n",
      "[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,0,3,4,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,6,0,7,0,0,0,0,0,0,0,0,8,9,0,10,0,0,0,0],\"[Rook,(1,0),(3,0),(4,0)]\",[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,2,0,3,0,0,0,0,4,0,0,0,0,0,0,5,0,0,0,0,0,6,0,7,0,0,0,0,0,0,0,0,8,9,0,10,0,0,0,0]]\t2\r\n",
      "[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,0,3,4,5,0,6,0,0,0,0,0,0,0,7,0,0,0,0,8,0,0,0,0,0,0,9,0,0,0,0,0,0,0,0,0,0,0,0],\"[Rook,(1,0),(3,7),(4,7)]\",[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,2,0,3,4,5,0,0,0,0,0,0,0,0,0,6,0,0,0,0,7,0,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0]]\t2\r\n",
      "[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,3,0,4,5,0,6,0,0,0,0,0,7,0,0,0,0,8,0,0,0,9,0,0,0,0,0,0,0,0,0,10,0,0,0,0,0,0,0],\"[Queen,(1,1),(5,6),(6,7)]\",[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,3,0,4,5,0,6,0,0,0,7,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,10,0,0,0,0,0,0,0]]\t2\r\n",
      "[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,3,0,4,5,0,6,0,0,0,0,7,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,9,0,10,0,0,0,0,11,0,0,0],\"[King,(1,-1),(3,2),(4,1)]\",[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,2,0,0,3,4,0,5,0,6,0,0,7,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,9,0,10,0,0,0,0,11,0,0,0]]\t2\r\n",
      "[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,3,0,4,5,0,6,0,0,0,0,7,0,0,8,0,0,0,9,0,10,0,0,0,0,0,0,0,11,0,12,0,0,0,0,13,0,0,0],\"[Knight,(1,2),(5,5),(6,7)]\",[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,3,0,4,5,0,6,0,0,0,0,7,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,9,0,10,0,0,0,0,11,0,0,0]]\t2\r\n",
      "[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,3,0,4,5,0,6,0,0,0,7,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,10,0,0,0,0,0,0,0],\"[Bishop,(1,-1),(4,5),(5,4)]\",[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,2,3,0,0,4,5,0,6,0,0,0,7,0,0,0,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0,0,9,10,0,0,0,0,0,0,0]]\t2\r\n",
      "[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,2,3,0,0,0,4,5,6,0,0,0,7,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0,0,9,0,0,0,0],\"[Pawn,(1,0),(4,6),(5,6)]\",[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,2,0,3,4,0,0,0,0,5,0,0,0,0,6,0,0,0,7,0,8,0,0,0,0,0,0,0,0,0,0,9,0,0,0,0]]\t2\r\n",
      "[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,2,0,3,4,0,0,0,0,5,0,0,0,0,6,0,0,0,7,0,8,0,0,0,0,0,0,0,0,0,0,9,0,0,0,0],\"[Rook,(1,0),(2,7),(3,7)]\",[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,2,3,0,0,4,0,5,0,0,0,0,0,0,0,0,6,0,7,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0]]\t2\r\n",
      "[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,2,3,0,4,0,0,5,6,0,0,7,0,0,0,0,0,0,0,0,8,0,0,0,0,0,9,10,0,0,0,0,11,0,0,0,0,0,0,0],\"[Pawn,(1,0),(4,3),(5,3)]\",[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,2,3,0,4,0,0,5,6,0,0,0,0,0,0,0,0,0,0,7,8,0,0,0,0,0,9,10,0,0,0,0,11,0,0,0,0,0,0,0]]\t2\r\n"
     ]
    }
   ],
   "source": [
    "!head \"/data_data/reinforcement_learning/results/state_transition_sarsa_2M.tsv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one-hot encode average values for state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,2,3,0,0,4,0,5,0,0,0,0,0,0,0,0,6,0,7,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0]\t0.012451\r\n",
      "[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,0,3,4,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,6,0,7,0,0,0,0,0,0,0,0,8,9,0,10,0,0,0,0]\t0.435902\r\n",
      "[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,0,3,4,5,0,6,0,0,0,0,0,0,0,7,0,0,0,0,8,0,0,0,0,0,0,9,0,0,0,0,0,0,0,0,0,0,0,0]\t1.398434\r\n",
      "[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,3,0,4,5,0,6,0,0,0,0,0,7,0,0,0,0,8,0,0,0,9,0,0,0,0,0,0,0,0,0,10,0,0,0,0,0,0,0]\t0.206993\r\n"
     ]
    }
   ],
   "source": [
    "! head -n 4 /data_data/reinforcement_learning/results/state_avg_value_sarsa_2M.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_state_values_file  = \"/data_data/reinforcement_learning/results/state_avg_value_sarsa_2M.tsv\"\n",
    "\n",
    "state_values_dict = defaultdict()\n",
    "\n",
    "with open(avg_state_values_file,'r') as avg_state_val_file:\n",
    "    \n",
    "    avg_state_values = avg_state_val_file.readlines()\n",
    "    \n",
    "    for avg_state_val in avg_state_values:\n",
    "        \n",
    "        try:\n",
    "\n",
    "            state_, avg_val_ = avg_state_val.split(\"\\t\") \n",
    "\n",
    "            state = unique_states_dict[state_]\n",
    "\n",
    "            state_values_dict[state] = float(avg_val_)\n",
    "        \n",
    "        except:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(114697411, 0.012451),\n",
       " (114697410, 0.435902),\n",
       " (114697409, 1.398434),\n",
       " (114697408, 0.206993),\n",
       " (114697407, 0.003296)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(state_values_dict.items())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### create one-hoe encoded transition matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,2,3,0,0,4,0,5,0,0,0,0,0,0,0,0,6,0,7,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0],\"[Bishop,(1,1),(4,0),(5,1)]\",[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,2,0,0,0,3,0,4,0,0,0,5,0,0,0,0,6,0,7,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0]]\t2\r\n",
      "[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,0,3,4,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,6,0,7,0,0,0,0,0,0,0,0,8,9,0,10,0,0,0,0],\"[Rook,(1,0),(3,0),(4,0)]\",[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,2,0,3,0,0,0,0,4,0,0,0,0,0,0,5,0,0,0,0,0,6,0,7,0,0,0,0,0,0,0,0,8,9,0,10,0,0,0,0]]\t2\r\n",
      "[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,0,3,4,5,0,6,0,0,0,0,0,0,0,7,0,0,0,0,8,0,0,0,0,0,0,9,0,0,0,0,0,0,0,0,0,0,0,0],\"[Rook,(1,0),(3,7),(4,7)]\",[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,2,0,3,4,5,0,0,0,0,0,0,0,0,0,6,0,0,0,0,7,0,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0]]\t2\r\n",
      "[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,3,0,4,5,0,6,0,0,0,0,0,7,0,0,0,0,8,0,0,0,9,0,0,0,0,0,0,0,0,0,10,0,0,0,0,0,0,0],\"[Queen,(1,1),(5,6),(6,7)]\",[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,3,0,4,5,0,6,0,0,0,7,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,10,0,0,0,0,0,0,0]]\t2\r\n",
      "[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,3,0,4,5,0,6,0,0,0,0,7,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,9,0,10,0,0,0,0,11,0,0,0],\"[King,(1,-1),(3,2),(4,1)]\",[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,2,0,0,3,4,0,5,0,6,0,0,7,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,9,0,10,0,0,0,0,11,0,0,0]]\t2\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 \"/data_data/reinforcement_learning/results/state_transition_sarsa_2M.tsv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Option I <= fix issue of groupby (s,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sas_trans_dict[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/data_data/reinforcement_learning/results/state_transition_one_hot_2M.tsv': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "damping_factor = 5\n",
    "\n",
    "default_freq   = 30\n",
    "\n",
    "sas_transitions_dict = defaultdict()\n",
    "\n",
    "\n",
    "!rm \"/data_data/reinforcement_learning/results/state_transition_one_hot_2M.tsv\"\n",
    "\n",
    "state_transitions_file_verbose = \"/data_data/reinforcement_learning/results/state_transition_sarsa_2M.tsv\"\n",
    "\n",
    "state_transitions_file_1_hot   = \"/data_data/reinforcement_learning/results/state_transition_one_hot_2M.tsv\"\n",
    "\n",
    "!touch \"/data_data/reinforcement_learning/results/state_transition_one_hot_2M.tsv\"\n",
    "\n",
    "new_state_starting_index = total_transitions + 10000000000\n",
    "\n",
    "with open(state_transitions_file_verbose,'r') as verbose_transitions_file:\n",
    "    \n",
    "    verbose_transitions = verbose_transitions_file.readlines()\n",
    "    \n",
    "    #with open(state_transitions_file_1_hot, 'a') as one_hot_transitions_file:\n",
    "        \n",
    "    for verbose_transition in verbose_transitions:\n",
    "            \n",
    "            transitions_, frequency_ = verbose_transition.split(\"\\t\")\n",
    "            \n",
    "            transitions = ast.literal_eval(transitions_)\n",
    "            \n",
    "            try:\n",
    "                state   = unique_states_dict[str(transitions[0])]\n",
    "            except:\n",
    "                unique_states_dict[str(transitions[0])] = new_state_starting_index\n",
    "                new_state_starting_index += 1\n",
    "                \n",
    "            try:\n",
    "                state_prime = unique_states_dict[str(transitions[2])]\n",
    "            except:\n",
    "                unique_states_dict[str(transitions[2])] = new_state_starting_index\n",
    "                new_state_starting_index += 1\n",
    "            try:\n",
    "                transition_frequency = round(int(frequency_)/int(sa_transition_probs[str(ast.literal_eval(transitions_)[:2])]+ damping_factor), 8)\n",
    "            except:\n",
    "                transition_frequency = round(int(frequency_)/20)\n",
    "            \n",
    "            action = transitions[1]\n",
    "            \n",
    "            try:\n",
    "                value_prime  = state_values_dict[state]\n",
    "                \n",
    "            except:\n",
    "                value_prime  = 0\n",
    "                \n",
    "            try:\n",
    "                score_prime  = float(value_prime*transition_frequency) \n",
    "            except:\n",
    "                score_prime  = 0\n",
    "                \n",
    "            try:\n",
    "                \n",
    "                transition = {action: score_prime}\n",
    "                \n",
    "                if not state in sas_transitions_dict.keys():\n",
    "                    \n",
    "                    sas_transitions_dict[state] = {}\n",
    "\n",
    "                sas_transitions_dict[state].update(transition)\n",
    "\n",
    "\n",
    "            except:\n",
    "                print(\"state:\\t{}\\taction:\\t{}\\t state_prime:\\{}\\t FAILED\".format(state, action, state_prime))\n",
    "                    \n",
    "with open(state_transitions_file_1_hot, 'a') as one_hot_transitions_file:\n",
    "        one_hot_transitions_file.write(json.dumps(sas_transitions_dict))\n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NUM_MOVES\\tNUM_STATES\")\n",
    "for i in range(0,50):\n",
    "    num_states = len(list([x for x in sas_transitions_dict.values() if len(x.items()) == i]))\n",
    "    print(\"{}\\t\\t{}\".format(i,num_states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list([x for x in sas_transitions_dict.values() if len(x.items()) > 20])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sas_transitions_dict[4554341]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tail -n 50 /data_data/reinforcement_learning/results/state_transition_one_hot_2M.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tail -n 5000 /data_data/reinforcement_learning/results/state_transition_one_hot_2M.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Spark -- Evaluate Memory Based operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "APP_NAME = \"Policy Evaluation - Chessy\"\n",
    "\n",
    "try:\n",
    "    sc.stop()\n",
    "    spark.stop()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "from pyspark import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "\n",
    "    \n",
    "sc = SparkContext(conf = SparkConf() \n",
    "                  .set(\"spark.driver.maxResultSize\", \"40g\") \n",
    "                  .set(\"spark.sql.execution.arrow.enabled\", \"true\") \n",
    "                  .set('spark.sql.broadcastTimeout', 1000) \n",
    "                  .set('spark.local.dir', '/data_data/session_length/spark_tmp/') \n",
    "                  .set('spark.driver.memory', '60G') \n",
    "                  .set(\"spark.executor.instances\", \"20\") \n",
    "                  .set(\"spark.executor.cores\", 16) \n",
    "                  .set(\"spark.executor.memory\", \"10G\")).getOrCreate()\n",
    "spark = SparkSession(sc)\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructField, StructType, StringType, LongType, DateType, DoubleType, IntegerType, ArrayType\n",
    "from pyspark.sql.functions import count, mean, stddev_pop, min, max, lit, round, bround, pow, col, corr, lower, upper, avg, stddev, abs, log\n",
    "from pyspark.sql.functions import lit, trim, rtrim, rpad, trim, coalesce\n",
    "from pyspark.sql.functions import current_date, current_timestamp, date_add, date_sub, months_between, to_date\n",
    "from pyspark.sql.functions import udf, col, sum, from_json\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import desc, dense_rank, rank, expr, split, regexp_replace\n",
    "\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import RFormula\n",
    "from pyspark.ml.classification import LogisticRegression, GBTClassifier, DecisionTreeClassifier, RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.regression import RandomForestRegressor, GBTRegressor\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.local.dir', '/data_data/session_length/spark_tmp/'),\n",
       " ('spark.sql.execution.arrow.enabled', 'true'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.app.name', 'pyspark-shell'),\n",
       " ('spark.executor.instances', '20'),\n",
       " ('spark.driver.port', '40991'),\n",
       " ('spark.driver.host', '192.168.1.101'),\n",
       " ('spark.driver.maxResultSize', '40g'),\n",
       " ('spark.executor.memory', '10G'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.executor.cores', '16'),\n",
       " ('spark.master', 'local[*]'),\n",
       " ('spark.driver.memory', '60G'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.sql.broadcastTimeout', '1000'),\n",
       " ('spark.ui.showConsoleProgress', 'true'),\n",
       " ('spark.app.id', 'local-1588906700495')]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc._conf.getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 5 \"/data_data/reinforcement_learning/results/state_transition_sarsa_2M.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,2,3,0,0,4,0,5,0,0,0,0,0,0,0,0,6,0,7,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0],\"[Bishop,(1,1),(4,0),(5,1)]\",[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,2,0,0,0,3,0,4,0,0,0,5,0,0,0,0,6,0,7,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0]]\t2\r\n",
      "[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,0,3,4,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,6,0,7,0,0,0,0,0,0,0,0,8,9,0,10,0,0,0,0],\"[Rook,(1,0),(3,0),(4,0)]\",[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,2,0,3,0,0,0,0,4,0,0,0,0,0,0,5,0,0,0,0,0,6,0,7,0,0,0,0,0,0,0,0,8,9,0,10,0,0,0,0]]\t2\r\n",
      "[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,0,3,4,5,0,6,0,0,0,0,0,0,0,7,0,0,0,0,8,0,0,0,0,0,0,9,0,0,0,0,0,0,0,0,0,0,0,0],\"[Rook,(1,0),(3,7),(4,7)]\",[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,2,0,3,4,5,0,0,0,0,0,0,0,0,0,6,0,0,0,0,7,0,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0]]\t2\r\n",
      "[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,3,0,4,5,0,6,0,0,0,0,0,7,0,0,0,0,8,0,0,0,9,0,0,0,0,0,0,0,0,0,10,0,0,0,0,0,0,0],\"[Queen,(1,1),(5,6),(6,7)]\",[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,3,0,4,5,0,6,0,0,0,7,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,10,0,0,0,0,0,0,0]]\t2\r\n",
      "[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,3,0,4,5,0,6,0,0,0,0,7,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,9,0,10,0,0,0,0,11,0,0,0],\"[King,(1,-1),(3,2),(4,1)]\",[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,2,0,0,3,4,0,5,0,6,0,0,7,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,9,0,10,0,0,0,0,11,0,0,0]]\t2\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 \"/data_data/reinforcement_learning/results/state_transition_sarsa_2M.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!head -n 50 \"/data_data/reinforcement_learning/results/state_transition_sarsa_2M.tsv\" >> test_import.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "SARF_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def import_sarsa_data():\n",
    "    global SARF_df\n",
    "    print(\"====================================================================================================================\")\n",
    "    print(\"====================================state_avg_value_sarsa_2M.tsv====================================================\")\n",
    "    print(\"==================================================================================================================\\n\\n\")\n",
    "    DRLSchema = StructType([\\\n",
    "        StructField('SAS',  StringType(), True),\\\n",
    "        StructField('frequency',  IntegerType(), True)])\n",
    "    \n",
    "    SARF = spark.read.format('csv').schema(DRLSchema).option(\"sep\",\"\\t\").load('test_import.tsv')\n",
    "    SARF.show(5,False)\n",
    "\n",
    "    \n",
    "    SARF_df = SARF.withColumn('stateprior', split(SARF['SAS'], '\\]')).withColumn('state_prior', regexp_replace(col('stateprior')[0], \"\\[\\[\", \"\")).withColumn('action', regexp_replace(col('stateprior')[1], \"\\,\\\"\\[\", \"\")).withColumn('state_prime', regexp_replace(col('stateprior')[2], \"\\\",\\[\", \"\")).drop('stateprior').drop('SAS')\n",
    "    SARF_df.show(5,False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================================\n",
      "====================================state_avg_value_sarsa_2M.tsv====================================================\n",
      "==================================================================================================================\n",
      "\n",
      "\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+\n",
      "|SAS                                                                                                                                                                                                                                                                                                  |frequency|\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+\n",
      "|[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,2,3,0,0,4,0,5,0,0,0,0,0,0,0,0,6,0,7,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0],\"[Bishop,(1,1),(4,0),(5,1)]\",[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,2,0,0,0,3,0,4,0,0,0,5,0,0,0,0,6,0,7,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0]]   |2        |\n",
      "|[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,0,3,4,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,6,0,7,0,0,0,0,0,0,0,0,8,9,0,10,0,0,0,0],\"[Rook,(1,0),(3,0),(4,0)]\",[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,2,0,3,0,0,0,0,4,0,0,0,0,0,0,5,0,0,0,0,0,6,0,7,0,0,0,0,0,0,0,0,8,9,0,10,0,0,0,0]]   |2        |\n",
      "|[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,0,3,4,5,0,6,0,0,0,0,0,0,0,7,0,0,0,0,8,0,0,0,0,0,0,9,0,0,0,0,0,0,0,0,0,0,0,0],\"[Rook,(1,0),(3,7),(4,7)]\",[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,2,0,3,4,5,0,0,0,0,0,0,0,0,0,6,0,0,0,0,7,0,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0]]     |2        |\n",
      "|[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,3,0,4,5,0,6,0,0,0,0,0,7,0,0,0,0,8,0,0,0,9,0,0,0,0,0,0,0,0,0,10,0,0,0,0,0,0,0],\"[Queen,(1,1),(5,6),(6,7)]\",[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,3,0,4,5,0,6,0,0,0,7,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,10,0,0,0,0,0,0,0]]  |2        |\n",
      "|[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,3,0,4,5,0,6,0,0,0,0,7,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,9,0,10,0,0,0,0,11,0,0,0],\"[King,(1,-1),(3,2),(4,1)]\",[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,2,0,0,3,4,0,5,0,6,0,0,7,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,9,0,10,0,0,0,0,11,0,0,0]]|2        |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---------+---------------------------------------------------------------------------------------------------------------------------------+------------------------+---------------------------------------------------------------------------------------------------------------------------------+\n",
      "|frequency|state_prior                                                                                                                      |action                  |state_prime                                                                                                                      |\n",
      "+---------+---------------------------------------------------------------------------------------------------------------------------------+------------------------+---------------------------------------------------------------------------------------------------------------------------------+\n",
      "|2        |0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,2,3,0,0,4,0,5,0,0,0,0,0,0,0,0,6,0,7,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0  |Bishop,(1,1),(4,0),(5,1)|0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,2,0,0,0,3,0,4,0,0,0,5,0,0,0,0,6,0,7,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0  |\n",
      "|2        |0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,0,3,4,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,6,0,7,0,0,0,0,0,0,0,0,8,9,0,10,0,0,0,0 |Rook,(1,0),(3,0),(4,0)  |0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,2,0,3,0,0,0,0,4,0,0,0,0,0,0,5,0,0,0,0,0,6,0,7,0,0,0,0,0,0,0,0,8,9,0,10,0,0,0,0 |\n",
      "|2        |0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,0,3,4,5,0,6,0,0,0,0,0,0,0,7,0,0,0,0,8,0,0,0,0,0,0,9,0,0,0,0,0,0,0,0,0,0,0,0  |Rook,(1,0),(3,7),(4,7)  |0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,2,0,3,4,5,0,0,0,0,0,0,0,0,0,6,0,0,0,0,7,0,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0  |\n",
      "|2        |0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,3,0,4,5,0,6,0,0,0,0,0,7,0,0,0,0,8,0,0,0,9,0,0,0,0,0,0,0,0,0,10,0,0,0,0,0,0,0 |Queen,(1,1),(5,6),(6,7) |0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,3,0,4,5,0,6,0,0,0,7,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,10,0,0,0,0,0,0,0 |\n",
      "|2        |0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,3,0,4,5,0,6,0,0,0,0,7,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,9,0,10,0,0,0,0,11,0,0,0|King,(1,-1),(3,2),(4,1) |0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,2,0,0,3,4,0,5,0,6,0,0,7,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,9,0,10,0,0,0,0,11,0,0,0|\n",
      "+---------+---------------------------------------------------------------------------------------------------------------------------------+------------------------+---------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import_sarsa_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,2,3,0,0,4,0,5,0,0,0,0,0,0,0,0,6,0,7,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0]\t0.012451\r\n",
      "[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,0,3,4,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,6,0,7,0,0,0,0,0,0,0,0,8,9,0,10,0,0,0,0]\t0.435902\r\n",
      "[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,0,3,4,5,0,6,0,0,0,0,0,0,0,7,0,0,0,0,8,0,0,0,0,0,0,9,0,0,0,0,0,0,0,0,0,0,0,0]\t1.398434\r\n",
      "[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,3,0,4,5,0,6,0,0,0,0,0,7,0,0,0,0,8,0,0,0,9,0,0,0,0,0,0,0,0,0,10,0,0,0,0,0,0,0]\t0.206993\r\n",
      "[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,3,0,4,5,0,6,0,0,0,0,7,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,9,0,10,0,0,0,0,11,0,0,0]\t0.003296\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 /data_data/reinforcement_learning/results/state_avg_value_sarsa_2M.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 20 /data_data/reinforcement_learning/results/history_sarsa_2M_test.tsv > sample_sarsa_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"game\": {\"0\":{\"state\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1],\"action\":\"[Knight,(2,-1),(0,1),(2,0)]\",\"state_prime\":[1,0,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,0,0,0,0,0,-15,-14,-13,-12,-11,-10,-9,-8,-7,0,-6,-5,-4,-3,-2,-1],\"reward\":0,\"Value\":0.637459}},\r\n",
      " {\"0\":{\"state\":[1,0,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,0,0,0,0,0,-15,-14,-13,-12,-11,-10,-9,-8,-7,0,-6,-5,-4,-3,-2,-1],\"action\":\"[Knight,(1,2),(2,0),(3,2)]\",\"state_prime\":[1,0,2,3,4,5,6,7,8,9,10,11,12,13,14,15,0,0,0,0,0,0,0,0,0,0,16,-16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-15,-14,-13,-12,-11,-10,-9,-8,-7,0,-6,-5,-4,-3,-2,-1],\"reward\":0,\"Value\":1.274919}},\r\n",
      " {\"0\":{\"state\":[1,0,2,3,4,5,6,7,8,9,10,11,12,13,14,15,0,0,0,0,0,0,0,0,0,0,16,-16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-15,-14,-13,-12,-11,-10,-9,-8,-7,0,-6,-5,-4,-3,-2,-1],\"action\":\"[Knight,(2,1),(0,6),(2,7)]\",\"state_prime\":[1,0,2,3,4,5,0,6,7,8,9,10,11,12,13,14,0,0,0,0,0,0,0,15,0,0,16,-16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-15,0,0,0,-14,-13,-12,0,-11,-10,-9,-8,-7,0,-6,-5,-4,-3,-2,-1],\"reward\":0,\"Value\":2.549837}},\r\n",
      " {\"0\":{\"state\":[1,0,2,3,4,5,0,6,7,8,9,10,11,12,13,14,0,0,0,0,0,0,0,15,0,0,16,-16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-15,0,0,0,-14,-13,-12,0,-11,-10,-9,-8,-7,0,-6,-5,-4,-3,-2,-1],\"action\":\"[Pawn,(1,1),(1,0),(2,1)]\",\"state_prime\":[1,0,2,3,4,5,0,6,0,7,8,9,10,11,12,13,0,14,0,0,0,0,0,15,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,0,0,0,-15,-14,-13,0,-12,-11,-10,-9,-8,0,-7,-6,-5,-4,-3,-2],\"reward\":0,\"Value\":5.099674}},\r\n",
      " {\"0\":{\"state\":[1,0,2,3,4,5,0,6,0,7,8,9,10,11,12,13,0,14,0,0,0,0,0,15,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,0,0,0,-15,-14,-13,0,-12,-11,-10,-9,-8,0,-7,-6,-5,-4,-3,-2],\"action\":\"[Knight,(1,2),(3,2),(4,4)]\",\"state_prime\":[1,0,2,3,4,5,0,6,0,7,8,9,10,11,12,13,0,14,0,0,0,0,0,15,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,-16,-15,0,0,-14,-13,-12,0,-11,-10,-9,-8,-7,0,-6,-5,-4,-3,0,-2],\"reward\":0,\"Value\":0.199349}},\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!head json_import_test.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "SARSA = None\n",
    "\n",
    "def import_sarsa_data():\n",
    "    global SARSA\n",
    "    print(\"====================================================================================================================\")\n",
    "    print(\"==================================== history_sarsa_2M_test.tsv​ ====================================================\")\n",
    "    print(\"====================================================================================================================\\n\\n\")\n",
    "    DRLSchema = StructType([\\\n",
    "        StructField('Null',  StringType(), True),\\\n",
    "        StructField('SARSA',  StringType(), True)])\n",
    "    \n",
    "    SARSA = spark.read.format('csv').schema(DRLSchema).option(\"sep\",\"\\t\").load('sample_sarsa_json')\n",
    "    SARSA.show(5,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================================\n",
      "==================================== history_sarsa_2M_test.tsv​ ====================================================\n",
      "====================================================================================================================\n",
      "\n",
      "\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|Null                                                                                                                                                                                                                                                                                                                                                                                                                             |SARSA|\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "| {\"0\":{\"state\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1],\"action\":\"[Knight,(2,-1),(0,1),(2,0)]\",\"state_prime\":[1,0,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,0,0,0,0,0,-15,-14,-13,-12,-11,-10,-9,-8,-7,0,-6,-5,-4,-3,-2,-1],\"reward\":0,\"Value\":0.637459}}|null |\n",
      "| {\"0\":{\"state\":[1,0,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,0,0,0,0,0,-15,-14,-13,-12,-11,-10,-9,-8,-7,0,-6,-5,-4,-3,-2,-1],\"action\":\"[Knight,(1,2),(2,0),(3,2)]\",\"state_prime\":[1,0,2,3,4,5,6,7,8,9,10,11,12,13,14,15,0,0,0,0,0,0,0,0,0,0,16,-16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-15,-14,-13,-12,-11,-10,-9,-8,-7,0,-6,-5,-4,-3,-2,-1],\"reward\":0,\"Value\":1.274919}} |null |\n",
      "| {\"0\":{\"state\":[1,0,2,3,4,5,6,7,8,9,10,11,12,13,14,15,0,0,0,0,0,0,0,0,0,0,16,-16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-15,-14,-13,-12,-11,-10,-9,-8,-7,0,-6,-5,-4,-3,-2,-1],\"action\":\"[Knight,(2,1),(0,6),(2,7)]\",\"state_prime\":[1,0,2,3,4,5,0,6,7,8,9,10,11,12,13,14,0,0,0,0,0,0,0,15,0,0,16,-16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-15,0,0,0,-14,-13,-12,0,-11,-10,-9,-8,-7,0,-6,-5,-4,-3,-2,-1],\"reward\":0,\"Value\":2.549837}} |null |\n",
      "| {\"0\":{\"state\":[1,0,2,3,4,5,0,6,7,8,9,10,11,12,13,14,0,0,0,0,0,0,0,15,0,0,16,-16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-15,0,0,0,-14,-13,-12,0,-11,-10,-9,-8,-7,0,-6,-5,-4,-3,-2,-1],\"action\":\"[Pawn,(1,1),(1,0),(2,1)]\",\"state_prime\":[1,0,2,3,4,5,0,6,0,7,8,9,10,11,12,13,0,14,0,0,0,0,0,15,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,0,0,0,-15,-14,-13,0,-12,-11,-10,-9,-8,0,-7,-6,-5,-4,-3,-2],\"reward\":0,\"Value\":5.099674}}    |null |\n",
      "| {\"0\":{\"state\":[1,0,2,3,4,5,0,6,0,7,8,9,10,11,12,13,0,14,0,0,0,0,0,15,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,0,0,0,-15,-14,-13,0,-12,-11,-10,-9,-8,0,-7,-6,-5,-4,-3,-2],\"action\":\"[Knight,(1,2),(3,2),(4,4)]\",\"state_prime\":[1,0,2,3,4,5,0,6,0,7,8,9,10,11,12,13,0,14,0,0,0,0,0,15,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,-16,-15,0,0,-14,-13,-12,0,-11,-10,-9,-8,-7,0,-6,-5,-4,-3,0,-2],\"reward\":0,\"Value\":0.199349}}   |null |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import_sarsa_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+---------+\n",
      "|Null                                                                                                                                                                                                                                                                                                                                                                                                                             |SARSA|new_SARSA|\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+---------+\n",
      "| {\"0\":{\"state\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,-15,-14,-13,-12,-11,-10,-9,-8,-7,-6,-5,-4,-3,-2,-1],\"action\":\"[Knight,(2,-1),(0,1),(2,0)]\",\"state_prime\":[1,0,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,0,0,0,0,0,-15,-14,-13,-12,-11,-10,-9,-8,-7,0,-6,-5,-4,-3,-2,-1],\"reward\":0,\"Value\":0.637459}}|null |null     |\n",
      "| {\"0\":{\"state\":[1,0,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,0,0,0,0,0,-15,-14,-13,-12,-11,-10,-9,-8,-7,0,-6,-5,-4,-3,-2,-1],\"action\":\"[Knight,(1,2),(2,0),(3,2)]\",\"state_prime\":[1,0,2,3,4,5,6,7,8,9,10,11,12,13,14,15,0,0,0,0,0,0,0,0,0,0,16,-16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-15,-14,-13,-12,-11,-10,-9,-8,-7,0,-6,-5,-4,-3,-2,-1],\"reward\":0,\"Value\":1.274919}} |null |null     |\n",
      "| {\"0\":{\"state\":[1,0,2,3,4,5,6,7,8,9,10,11,12,13,14,15,0,0,0,0,0,0,0,0,0,0,16,-16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-15,-14,-13,-12,-11,-10,-9,-8,-7,0,-6,-5,-4,-3,-2,-1],\"action\":\"[Knight,(2,1),(0,6),(2,7)]\",\"state_prime\":[1,0,2,3,4,5,0,6,7,8,9,10,11,12,13,14,0,0,0,0,0,0,0,15,0,0,16,-16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-15,0,0,0,-14,-13,-12,0,-11,-10,-9,-8,-7,0,-6,-5,-4,-3,-2,-1],\"reward\":0,\"Value\":2.549837}} |null |null     |\n",
      "| {\"0\":{\"state\":[1,0,2,3,4,5,0,6,7,8,9,10,11,12,13,14,0,0,0,0,0,0,0,15,0,0,16,-16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-15,0,0,0,-14,-13,-12,0,-11,-10,-9,-8,-7,0,-6,-5,-4,-3,-2,-1],\"action\":\"[Pawn,(1,1),(1,0),(2,1)]\",\"state_prime\":[1,0,2,3,4,5,0,6,0,7,8,9,10,11,12,13,0,14,0,0,0,0,0,15,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,0,0,0,-15,-14,-13,0,-12,-11,-10,-9,-8,0,-7,-6,-5,-4,-3,-2],\"reward\":0,\"Value\":5.099674}}    |null |null     |\n",
      "| {\"0\":{\"state\":[1,0,2,3,4,5,0,6,0,7,8,9,10,11,12,13,0,14,0,0,0,0,0,15,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-16,0,0,0,-15,-14,-13,0,-12,-11,-10,-9,-8,0,-7,-6,-5,-4,-3,-2],\"action\":\"[Knight,(1,2),(3,2),(4,4)]\",\"state_prime\":[1,0,2,3,4,5,0,6,0,7,8,9,10,11,12,13,0,14,0,0,0,0,0,15,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,-16,-15,0,0,-14,-13,-12,0,-11,-10,-9,-8,-7,0,-6,-5,-4,-3,0,-2],\"reward\":0,\"Value\":0.199349}}   |null |null     |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = StructType(\n",
    "    [\n",
    "        StructField('state_prior', StringType(), True),\n",
    "        StructField('action',      StringType(), True),\n",
    "        StructField('state_prime', StringType(), True),\n",
    "        StructField('reward',      StringType(), True),\n",
    "        StructField('value',       StringType(), True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "SARSA.withColumn(\"new_SARSA\", from_json(\"SARSA\", schema))\\\n",
    "    .show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df = users_df.withColumnRenamed('userid','user_id')\n",
    "u = users_df.alias('u')\n",
    "s = sessions_DF.alias('s')\n",
    "join_condition = [ (u.user_id == s.userid) ]\n",
    "sessionsDF = s.join(u, join_condition, 'inner').drop('user_id')\n",
    "sessionsDF.show(20,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
